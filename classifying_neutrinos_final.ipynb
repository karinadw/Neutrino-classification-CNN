{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "18014458 - classifying neutrinos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOav1k21eunRvQaed9Lif3i",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karinadw/Neutrino-classification-CNN/blob/main/classifying_neutrinos_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNOpqLwlj6o-"
      },
      "source": [
        "# CLASSIYING NEUTRINOS IN A LONG BASE-LINE NEUTRINO OSCILLATION EXPERIMENT\r\n",
        "\r\n",
        "## Karina Dansinghani Wadhwani\r\n",
        "\r\n",
        "## Student number: 18014458 \r\n",
        "\r\n",
        "## Date: January 2021\r\n",
        "\r\n",
        "The code to conduct this project was discussed with student Teresa Delgado de las Heras with student number 18079736."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqd4GNoiZYbp"
      },
      "source": [
        "# *INDEX*\r\n",
        "\r\n",
        "1. [Introduction](#intro)\r\n",
        "\r\n",
        "2. [Background and theory](#back)\r\n",
        "\r\n",
        "3. [Task 1: developing a classifier to identify $\\nu_\\mu$ CC events](#task1)\r\n",
        "\r\n",
        "  3.1 [Retrieving the data](#data)\r\n",
        "\r\n",
        "  3.2 [Binary classification](#binary)\r\n",
        "\r\n",
        "  3.3 [Balancing the data](#balance)\r\n",
        "\r\n",
        "  3.4 [Preparing the data](#prep)\r\n",
        "\r\n",
        "  3.5 [Multi-view Convolutional Neural Network](#CNN)\r\n",
        "\r\n",
        "4. [Task 2: investigating how the variables in the meta data affect the accuracy of the classifier](#task2)\r\n",
        "\r\n",
        "  4.1 [How to define the performance of the classifier?](#4.1)\r\n",
        "\r\n",
        "  4.2 [How well does the classifier perform on QE events vs DIS events?](#4.2)\r\n",
        "\r\n",
        "  4.3 [How well does the classifier perform on low energy neutrinos vs high energy neutrinos?](#4.3)\r\n",
        "\r\n",
        "  4.4 [How well does the classifier perform on low energy muons vs high energy muons?](#4.4)\r\n",
        "\r\n",
        "  4.5 [Which variables in the metadata does the classifier performance depend?](#4.5)\r\n",
        "\r\n",
        "5. [Extension 1: Machine learning algorithm to determine the energy of the neutrino](#extension1)\r\n",
        "\r\n",
        "6. [Extension 2: Machine learning algorithm to determine the flavour of the neutrino](#extension2)\r\n",
        "\r\n",
        "7. [Extension 3: Machine learning algorithm to determine $y=$ lepton energy over neutrino energy](#extension3)\r\n",
        "\r\n",
        "8. [Extension 5: Machine learning algorithm to determine the interaction mode](#extension5)\r\n",
        "\r\n",
        "8. [Conclusion](#conc)\r\n",
        "\r\n",
        "9. [References](#ref)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRruJq_RZdIS"
      },
      "source": [
        "<a name=\"intro\"></a>\r\n",
        "\r\n",
        "## 1. Introduction\r\n",
        "\r\n",
        "In the following project meta-data on neutrino events is going to be used to identify $\\nu_\\mu$ charged current events as well as to explore how the different variable of the meta data affect the results obtained. Some other classification tasks being done include a interaction mode classifier as well as a neutrino flavour classifier. Some regression tasks being done in the project are neutrino energy detection and lepton energy over neutrino energy detection. \r\n",
        "\r\n",
        "All of these are common tasks tackled within the computer science field of computer vision. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ21GLzmZyBG"
      },
      "source": [
        "<a name=\"back\"></a>\r\n",
        "\r\n",
        "## 2. Background and theory\r\n",
        "\r\n",
        "Particles in the Standard Model are classified into two categories: fermions and boson. All the particles in the Standard Model have an antiparticle, which has the same spin and mass as the particle but has opposite charge. Bosons have integer spin and are force carriers. Fermions have half-integer spin and are grouped into quarks and leptons. An example of a fermion is the electron. Muon (µ) and tau ($\\tau$) electrons are the two heavier counterparts of the electrons, which form the charged leptons along with their antiparticles. In a weak interaction, these charged leptons can couple to a neutrino forming the electron neutrino $\\nu_{\\mu}$, muon neutrino $\\nu_{e}$, and tau neutrino $\\nu_{\\tau}$. These three particles are types of neutrinos, also known as flavours.  \r\n",
        "\r\n",
        "The only neutrino interactions with matter that have been observed are mediated by the weak force through the exchange of either the $Z^0$ or $W^+$ bosons. Neutral current (NC) events are those interactions that are mediated by the $Z^0$ as it is neutral, while charged current (CC) events are mediated by the $W^+$ boson. Due to charge conservation, in an NC interaction the particle is left with its charge unchanged, therefore an interacting neutrino remains a neutrino. On the other hand, CC interactions undergo a change in charge, the interaction neutrino will transform into its lepton partner, leaving a signature of the flavour of the incoming neutrino. In terms of the nuclear side of the interaction, this can be a lot more complex. The simplest case occurs when the neutrino interacts without significant coupling to the nucleus with a single nucleon. This is considered an elastic interaction for NC events, while the CC events are referred to as a quasi-elastic interaction (QE) because the nucleon alters its form. Resonant production (RES) are those events in which a neutrino interaction may excite a resonance within the nucleus to create a hadron. Lastly, more complex scattering events are named deep-inelastic scattering (DIS), these produce significant disruption in the nuclear system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf0JNxR2jJ9S"
      },
      "source": [
        "<a name=\"task1\"></a>\r\n",
        "\r\n",
        "## 3. Task 1: developing a classifier to identify $\\nu_\\mu$ CC events"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGtv1cjWGHnD"
      },
      "source": [
        "The first part of this project consists of developing a machine learning classifier that will succesfully classify $\\nu_\\mu$ charged-current events. \r\n",
        "\r\n",
        "\r\n",
        "Image classification is a popular task tackled in the computer vision field of computer science, where the aim is to teach computers how to \"see\" as humans do. Recent emerging techonologies and advancement in machine learning has enabled this field to progress significantly with the breakthrough of Convolutional Neural Networks (CNN), inspired by animal visual cortex perception system. This is a deep neural network that is going to be used throughout the project for different tasks. \r\n",
        "\r\n",
        "For this specific task, a CNN is going to be used for a classification problem.\r\n",
        "The meta data available for this task contains information on the neutrino interaction and images of the x-z view and y-z view for each interaction. These will be used to train a multi-view CNN. \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "The first step is to import all the necessary modules. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FBom04jrZ6S"
      },
      "source": [
        "## IMPORTING ALL THE NECESSARY MODULES\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import h5py\r\n",
        "\r\n",
        "# TensorFlow and tf.keras\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation, concatenate, AveragePooling2D\r\n",
        "from keras.models import Model\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras import callbacks \r\n",
        "\r\n",
        "import matplotlib.style                     \r\n",
        "import matplotlib as mpl        \r\n",
        "\r\n",
        "# Necessary to retrieve the data\r\n",
        "import urllib.request   \r\n",
        "\r\n",
        "# Used to split data into training and testing data samples\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# Imports a progress bar\r\n",
        "from tqdm.notebook import tqdm              \r\n",
        "from IPython.display import display, Math\r\n",
        "\r\n",
        "# To be able to save the files from google colaboratory to my desktop \r\n",
        "from google.colab import files              \r\n",
        "\r\n",
        "# Set default figure size\r\n",
        "mpl.rcParams[\"legend.frameon\"] = False\r\n",
        "mpl.rcParams['figure.dpi'] = 200            # dots per inch\r\n",
        "\r\n",
        "# Useful for debugging problems\r\n",
        "print(\"Tensorflow version: \", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk-98en1yAkO"
      },
      "source": [
        "import enum \n",
        "class Interaction(enum.Enum):\n",
        "    kNumuQE =0            # Numu CC QE interaction\n",
        "    kNumuRes =1           # Numu CC Resonant interaction\n",
        "    kNumuDIS = 2          # Numu CC DIS interaction\n",
        "    kNumuOther = 3        # Numu CC, other than above\n",
        "    kNueQE = 4            # Nue CC QE interaction\n",
        "    kNueRes = 5           # Nue CC Resonant interaction\n",
        "    kNueDIS = 6           # Nue CC DIS interaction\n",
        "    kNueOther = 7         # Nue CC, other than above\n",
        "    kNutauQE = 8          # Nutau CC QE interaction\n",
        "    kNutauRes = 9         # Nutau CC Resonant interaction\n",
        "    kNutauDIS =10         # Nutau CC DIS interaction\n",
        "    kNutauOther =11       # Nutau CC, other than above\n",
        "    kNuElectronElastic = 12# NC Nu On E Scattering\n",
        "    kNC =13               # NC interaction\n",
        "    kCosmic =14           # Cosmic ray background\n",
        "    kOther =15            # Something else.  Tau?  Hopefully we don't use this\n",
        "    kNIntType=16          # Number of interaction types, used like a vector size\n",
        "\n",
        "    \n",
        "class FinalState(enum.Enum):\n",
        "    kNumu0tr0sh=0                    # Numu CC - no track no shower\n",
        "    kNumu0tr1sh=1                    # Numu CC - no track  1 shower\n",
        "    kNumu0tr2sh=enum.auto()          # Numu CC - no track  2 shower\n",
        "    kNumu0trMsh=enum.auto()          # Numu CC - no track 3+ shower\n",
        "    kNumu1tr0sh=enum.auto()          # Numu CC -  1 track no shower\n",
        "    kNumu1tr1sh=enum.auto()          # Numu CC -  1 track  1 shower\n",
        "    kNumu1tr2sh=enum.auto()          # Numu CC -  1 track  2 shower\n",
        "    kNumu1trMsh=enum.auto()          # Numu CC -  1 track 3+ shower\n",
        "    kNumu2tr0sh=enum.auto()          # Numu CC -  2 track no shower\n",
        "    kNumu2tr1sh=enum.auto()          # Numu CC -  2 track  1 shower\n",
        "    kNumu2tr2sh=enum.auto()          # Numu CC -  2 track  2 shower\n",
        "    kNumu2trMsh=enum.auto()          # Numu CC -  2 track 3+ shower\n",
        "    kNumuMtr0sh=enum.auto()          # Numu CC - 3+ track no shower\n",
        "    kNumuMtr1sh=enum.auto()          # Numu CC - 3+ track  1 shower\n",
        "    kNumuMtr2sh=enum.auto()          # Numu CC - 3+ track  2 showe\n",
        "    kNumuMtrMsh=enum.auto()          # Numu CC - 3+ track 3+ shower\n",
        "    kNue0tr0sh=enum.auto()           # Nue CC - no track no shower\n",
        "    kNue0tr1sh=enum.auto()           # Nue CC - no track  1 shower\n",
        "    kNue0tr2sh=enum.auto()           # Nue CC - no track  2 shower\n",
        "    kNue0trMsh=enum.auto()           # Nue CC - no track 3+ shower\n",
        "    kNue1tr0sh=enum.auto()           # Nue CC -  1 track no shower\n",
        "    kNue1tr1sh=enum.auto()           # Nue CC -  1 track  1 shower\n",
        "    kNue1tr2sh=enum.auto()           # Nue CC -  1 track  2 shower\n",
        "    kNue1trMsh=enum.auto()           # Nue CC -  1 track 3+ shower\n",
        "    kNue2tr0sh=enum.auto()           # Nue CC -  2 track no shower\n",
        "    kNue2tr1sh=enum.auto()           # Nue CC -  2 track  1 shower\n",
        "    kNue2tr2sh=enum.auto()           # Nue CC -  2 track  2 shower\n",
        "    kNue2trMsh=enum.auto()           # Nue CC -  2 track 3+ shower\n",
        "    kNueMtr0sh=enum.auto()           # Nue CC - 3+ track no shower\n",
        "    kNueMtr1sh=enum.auto()           # Nue CC - 3+ track  1 shower\n",
        "    kNueMtr2sh=enum.auto()           # Nue CC - 3+ track  2 shower\n",
        "    kNueMtrMsh=enum.auto()           # Nue CC - 3+ track 3+ shower\n",
        "    kNC0tr0sh=enum.auto()            # NC CC - no track no shower\n",
        "    kNC0tr1sh=enum.auto()            # NC CC - no track  1 shower\n",
        "    kNC0tr2sh=enum.auto()            # NC CC - no track  2 shower\n",
        "    kNC0trMsh=enum.auto()            # NC CC - no track 3+ shower\n",
        "    kNC1tr0sh=enum.auto()            # NC CC -  1 track no shower\n",
        "    kNC1tr1sh=enum.auto()            # NC CC -  1 track  1 shower\n",
        "    kNC1tr2sh=enum.auto()            # NC CC -  1 track  2 shower\n",
        "    kNC1trMsh=enum.auto()            # NC CC -  1 track 3+ shower\n",
        "    kNC2tr0sh=enum.auto()            # NC CC -  2 track no shower\n",
        "    kNC2tr1sh=enum.auto()            # NC CC -  2 track  1 shower\n",
        "    kNC2tr2sh=enum.auto()            # NC CC -  2 track  2 shower\n",
        "    kNC2trMsh=enum.auto()            # NC CC -  2 track 3+ shower\n",
        "    kNCMtr0sh=enum.auto()            # NC CC - 3+ track no shower\n",
        "    kNCMtr1sh=enum.auto()            # NC CC - 3+ track  1 shower\n",
        "    kNCMtr2sh=enum.auto()            # NC CC - 3+ track  2 shower\n",
        "    kNCMtrMsh=enum.auto()            # NC CC - 3+ track 3+ shower\n",
        "    kCosmicFS=enum.auto()            # Cosmic ray background\n",
        "    kOtherFS=enum.auto()             # Something else.  Tau?  Hopefully we don't use this\n",
        "    kNFStType=enum.auto()            # Number of interaction types, used like a vector size\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJR3fDBkPVIE"
      },
      "source": [
        "<a name=\"data\"></a>\r\n",
        "\r\n",
        "## 3.1 Retrieving the data\r\n",
        "\r\n",
        "There are 200 data files containing neutrino events in it. As these files are going to be used throughout the project and, in ocasions, more or less files may be needed, it is crucial to create a definition to retrieve as many data files needed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzwAi6_bsR9R"
      },
      "source": [
        "## CREATING A FUNCTION TO RETRIEVE THE DATA FILES\r\n",
        "\r\n",
        "def data_retriever(file_number):\r\n",
        "  \"\"\"\r\n",
        "  This function takes the number of files to be retrieved as an input and \r\n",
        "  retrieves the data and returns the file names in an array.  \r\n",
        "\r\n",
        "  Input:\r\n",
        "  - file_number: number of files to be retrieved.\r\n",
        "\r\n",
        "  Output:\r\n",
        "  - f_name = an array with the name of the files corresponding \r\n",
        "  to the number of files requested\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  # the link to the files we want to retrieve look like this:\r\n",
        "  # http://www.hep.ucl.ac.uk/undergrad/0056/other/projects/nova/neutrino1.h5\r\n",
        "  # the number after neutrino is the only thing that changes for the 200 files, \r\n",
        "  # a counter will be used to iterate over the different links\r\n",
        "\r\n",
        "  core = 'http://www.hep.ucl.ac.uk/undergrad/0056/other/projects/nova/neutrino'\r\n",
        "  counter = 1\r\n",
        "  end = '.h5'\r\n",
        "  f_name=[]  # empty array to store the name of the files being retreived \r\n",
        "  \r\n",
        "  # iterating over the number of files requested \r\n",
        "  for i in tqdm(range(0,file_number)):\r\n",
        "\r\n",
        "          filename = \"neutrino\" + str(counter) + \".h5\"                # obtaining the name of the link of the file \r\n",
        "          f_name.append(filename)                                     # appending the name to the array of filenames \r\n",
        "          urllib.request.urlretrieve(core+str(counter)+end, filename) # retriving the data of the files\r\n",
        "          counter += 1                                                # increasing the counter by 1 \r\n",
        "          \r\n",
        "  return (f_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DYWNvemoOw6"
      },
      "source": [
        "Now that we have a definition to retrieve the data, we can proceed to use it. After testing the performance of the network with several files, I have decided to use 7 files as using more did not change the performance significantly and it is computationally a lot more expensive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8cBpGTjsjhk"
      },
      "source": [
        "## RETRIEVING THE FILES FOR TASK 1 \r\n",
        "\r\n",
        "files = data_retriever(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MivD7i4vf2B"
      },
      "source": [
        "## 3.2 Binary classification \r\n",
        "\r\n",
        "In order to succesfully detect $\\nu_\\mu$ charged-current events, a binary classification has to be done. Binary classification is the process in which elements are groupes into two different sets on the basis of some classification rule. In this case the two groups are 0s and 1s, where the 1 represents the $\\nu_\\mu$ charged-current events and the 0 represents everything else. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1anr4HbO_A6N"
      },
      "source": [
        "## CHANGING LABELS FOR A BINARY CLASSIFICATION, 1 REPRESENTS MUON NEUTRINO CC EVENTS AND 0 REPRESENTS EVERYTHING ELSE. \r\n",
        "\r\n",
        "model_lab_imb = []                                                # empty array for the labels of the neutrino interactions, either 0s or 1s\r\n",
        "model_in_1_imb = []                                               # empty array for the x-z view of the neutrino interaction \r\n",
        "model_in_2_imb = []                                               # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for file_name in tqdm(files):\r\n",
        "\r\n",
        "    # opening the file in read only mode \r\n",
        "    df=h5py.File(file_name, 'r')\r\n",
        "    \r\n",
        "    # iterating over the length of cvnmap to obtain the labels and input images for each interaction \r\n",
        "    for i in range(len(df['cvnmap'])):\r\n",
        "      model = df['cvnmap'][i].reshape((2,100,80))                 # reshaping the images \r\n",
        "      model_in_1_imb.append(model[0])                             # apending the x-z view to the corresponding array\r\n",
        "      model_in_2_imb.append(model[1])                             # apending the y-z view to the corresponding array\r\n",
        "\r\n",
        "      if df['neutrino']['interaction'][i] <= 3:\r\n",
        "        model_lab_imb.append(int(1))                              # appending a 1 to the labels for muon neutrino CC events \r\n",
        "\r\n",
        "      else:\r\n",
        "        model_lab_imb.append(int(0))                              # appending a 0 to the labels for non muon neutrino CC events"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBD9qeLWVIxU"
      },
      "source": [
        "We are now going to plot the labels in a histogram. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS4L-9-yVNYV"
      },
      "source": [
        "# PLOTTING LABELS FOR BINARY CLASSIFICATION IN A HISTOGRAM\r\n",
        "\r\n",
        "plt.hist(model_lab_imb)                                       # calls the labels of the model \r\n",
        "plt.title('Labels for muon neutrino classification')          # adds a title \r\n",
        "plt.ylabel('Number of neutrino intercations')                 # adds a y label to the histogram\r\n",
        "plt.xlabel('Label')                                           # adds a y label to the histogram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVh07zXiYRmP"
      },
      "source": [
        "It can clearly be seen from the graph above that there is a significant data imbalance. This is due to the nature of these events. Detection of muon neutrino events is a lot higher than electron neutrino events. On the other hand, tau neutrino events have never even been detected, their existence has been infered. \r\n",
        "\r\n",
        "The percentage of each type of event in the loaded data files can be seen below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw8Vhxzckxhu"
      },
      "source": [
        "numu_counter = 0               # counter to keep track of how many muon neutrino CC events there are \r\n",
        "nue_counter = 0                # counter to keep track of how many electron neutrino CC events there are\r\n",
        "nutau_counter = 0              # counter to keep track of how many tau neutrino CC events there are\r\n",
        "other_counter = 0              # counter to keep track of how many other events there are\r\n",
        "\r\n",
        "# iterating over the loaded data files to obtain the number of each type of events \r\n",
        "for file_name in tqdm(files):\r\n",
        "\r\n",
        "  # opening the file in read mode only \r\n",
        "  df=h5py.File(file_name, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions in the data file \r\n",
        "  for i in range(len(df['cvnmap'])):\r\n",
        "\r\n",
        "    # if the neutrino interaction number is between 0 and/or equal to 3, \r\n",
        "    # the counter for muon neutrino events is increased by 1\r\n",
        "    if df['neutrino']['interaction'][i] <= 3:\r\n",
        "      numu_counter= numu_counter + 1\r\n",
        "\r\n",
        "    # if the neutrino interaction number is between 4 and/or equal to 7, \r\n",
        "    # the counter for electron neutrino events is increased by 1\r\n",
        "    elif df['neutrino']['interaction'][i] > 4 and df['neutrino']['interaction'][i] <= 7:\r\n",
        "      nue_counter= nue_counter + 1\r\n",
        "\r\n",
        "    # if the neutrino interaction number is between 7 and/or equal to 11, \r\n",
        "    # the counter for tau neutrino events is increased by 1\r\n",
        "    elif df['neutrino']['interaction'][i] > 7 and df['neutrino']['interaction'][i] <= 11:\r\n",
        "\r\n",
        "      nutau_counter= nutau_counter + 1\r\n",
        "\r\n",
        "    # for all other events the counter for other events is increased by 1 \r\n",
        "    else:\r\n",
        "\r\n",
        "      other_counter = other_counter + 1\r\n",
        "      \r\n",
        "# the total events adds all the events to get the total value of events in the data files \r\n",
        "totalevents = numu_counter + nue_counter + nutau_counter + other_counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBny_7h1ld0f"
      },
      "source": [
        "## DISPLAYING THE NUMBER OF EVENTS AND THEIR CORRESPONDING PERCENTAGES \r\n",
        "\r\n",
        "# Muon neutrino charged-current events information \r\n",
        "display(Math(r'There \\; are \\; {} \\; \\nu_\\mu \\; charged-current \\; events. \\; This \\; represents \\; {} \\% \\; of \\; the \\; events \\; in \\; {} \\; meta \\; data \\; files.'.format(numu_counter, round(((numu_counter / totalevents ) * 100),2), len(files))))\r\n",
        "\r\n",
        "# Tau neutrino charged-current events information \r\n",
        "display(Math(r'There \\; are \\; {} \\; \\nu_\\tau \\; charged-current \\; events. \\; This \\; represents \\; {} \\% \\; of \\; the \\; events \\; in \\; {} \\; meta \\; data \\; files.'.format(nutau_counter, round(((nutau_counter / totalevents ) * 100),2), len(files))))\r\n",
        "\r\n",
        "# Electron neutrino charged-current events information \r\n",
        "display(Math(r'There \\; are \\; {} \\; \\nu_e \\; charged-current \\; events. \\; This \\; represents \\; {} \\% \\; of \\; the \\; events \\; in \\; {} \\; meta \\; data \\; files.'.format(nue_counter, round(((nue_counter / totalevents ) * 100),2), len(files))))\r\n",
        "\r\n",
        "# Other events information \r\n",
        "display(Math(r'There \\; are \\; {} \\; other \\; events. \\; This \\; represents \\; {} \\% \\; of \\; the \\; events \\; in \\; {} \\; meta \\; data \\; files.'.format(other_counter, round(((other_counter / totalevents ) * 100),2), len(files))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEcwF9LMZGAS"
      },
      "source": [
        "Having this type of imabalance in the data set can lead to the accuracy paradox, where if we tried to classify, for example, electron neutrino CC events we would end up getting a higher accuracy in our model than for muon neutrino CC events, despite having more data for the latter. It is therefore important to make sure the dataset is balanced before proceeding. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDP9lpmfAajM"
      },
      "source": [
        "<a name=\"balance\"></a>\r\n",
        "\r\n",
        "## 3.3 Balancing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu_e_EKJqNrb"
      },
      "source": [
        "The method used to balance the data is as follows. All the data files are going to be loaded, then they are going to split into files that are going to be used to obtain muon neutrino charged-current events and files that will be used to obtain the data for non-muon neutrino charged-current events. As it can be seen from section 3.2, the imbalance is significant, there are a lot more muon netrino interactions. For this reason, more files are going to be used to iterate and get muon neutrino charged-current events and less files are going to be used for non-muon neutrino charged current events. \r\n",
        "\r\n",
        "After testing out different percentages, it was found that using 100% for the rest yielded in a balanced dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WwT7u--ZBS9"
      },
      "source": [
        "## SPLITTING THE DATA FILES \r\n",
        "\r\n",
        "# using 100% of the files for non muon neutrino CC events and 10% for the rest\r\n",
        "files_90, files_10 = train_test_split(files, train_size = 0.9, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua4fJ0AQOnJ1"
      },
      "source": [
        "Now that the files have been split, the same methodology as in section 3.2 will be used to label the events. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PliUciK7YVjF"
      },
      "source": [
        "## BINARY CLASSIFICATION AND BALANCING THE DATA \r\n",
        "# using 1s to label muon neutrino CC events and 0s to label the rest\r\n",
        "\r\n",
        "# empty arrays\r\n",
        "model_lab=[]                                                     # empty array for the labels of the neutrino interactions, either 0s or 1s \r\n",
        "model_in_1 = []                                                  # empty array for the x-z view of the neutrino interaction\r\n",
        "model_in_2 = []                                                  # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for file_name in tqdm(files):\r\n",
        "\r\n",
        "    # opening the file in read only mode \r\n",
        "    df=h5py.File(file_name, 'r')\r\n",
        "    \r\n",
        "    # iterating over the length of cvnmap to obtain the labels and input images for each interaction \r\n",
        "    for i in range(len(df['cvnmap'])):\r\n",
        "      \r\n",
        "      # if the interaction number is above 3 it is a non neutrino CC event\r\n",
        "      if df['neutrino']['interaction'][i] > 3:\r\n",
        "\r\n",
        "        model = df['cvnmap'][i].reshape((2,100,80))                 # reshaping the images \r\n",
        "        model_in_1.append(model[0])                                 # apending the x-z view to the corresponding array\r\n",
        "        model_in_2.append(model[1])                                 # apending the y-z view to the corresponding array\r\n",
        "        model_lab.append(int(0))                                    # appends a 0 to the labels array for non muon neutrino CC interactions\r\n",
        "\r\n",
        "      else:\r\n",
        "        pass\r\n",
        "\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for file_name in tqdm(files_10):\r\n",
        "\r\n",
        "    # opening the file in read only mode \r\n",
        "    df=h5py.File(file_name, 'r')\r\n",
        "    \r\n",
        "    # iterating over the length of cvnmap to obtain the labels and input images for each interaction \r\n",
        "    for j in range(len(df['cvnmap'])):\r\n",
        "      \r\n",
        "      # if the interaction number is below 3 it is a neutrino CC event\r\n",
        "      if df['neutrino']['interaction'][j] <= 3:\r\n",
        "\r\n",
        "        model = df['cvnmap'][j].reshape((2,100,80))                 # reshaping the images \r\n",
        "        model_in_1.append(model[0])                                 # apending the x-z view to the corresponding array\r\n",
        "        model_in_2.append(model[1])                                 # apending the y-z view to the corresponding array\r\n",
        "        model_lab.append(int(1))                                    # appends a 1 to the labels array for muon neutrino CC interactions\r\n",
        "\r\n",
        "      else:\r\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc1kCR6TVdm3"
      },
      "source": [
        "The balanced data set is going to be plotted in a histogram along with the imabalanced data set to check if it has been correctly balanced. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqUsxLD4INs7"
      },
      "source": [
        "## HISTOGRAMS OF BALANCED AND IMBALANCED DATASETS \r\n",
        "\r\n",
        "f = plt.figure(figsize=(20,7))           # sets the size of the histograms \r\n",
        "ax = f.add_subplot(121)                  # adds one plot \r\n",
        "ax2 = f.add_subplot(122)                 # adds a second plot next to the first one \r\n",
        "ax.hist(model_lab_imb)                   # the first histogram is the imbalanced labels \r\n",
        "ax.set_title('Imbalanced data set')      # adds a title to the histogram on the right \r\n",
        "ax2.hist(model_lab)                      # the first histogram is the balanced labels\r\n",
        "ax2.set_title('Balanced data set')       # adds a title to the histogram on the left\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5UFoUaijlRR"
      },
      "source": [
        "<a name=\"prep\"></a>\r\n",
        "\r\n",
        "## 3.4 Preparing the data\r\n",
        "\r\n",
        "Now that we have the labels, it is important to shuffle them as we have all the 0s at the beggining and all the 1s at the end of the array. In order to shuffle the labels, we must shuffle the images as well so that they are all shuffled together and the information is not mixed up. To do so, and as this will be necessary throughout the project, a function will be created. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AxOlANZwvaI"
      },
      "source": [
        "## FUNCTION TO SHUFFLE THE IMAGES AND LABELS TOGETHER \r\n",
        "\r\n",
        "def shuffle_data(labels, image_set_1, image_set_2):  \r\n",
        "  \r\n",
        "  \"\"\"\r\n",
        "  This function takes the labels and the two sets of corresponding images as an input and shuffles them together.  \r\n",
        "\r\n",
        "  Input:\r\n",
        "  - labels: labels of the neutrino interactions.\r\n",
        "  - image_set_1: images corresponding to the x-z view of the interaction.\r\n",
        "  - image_set_2: images corresponding to the y-z view of the interaction.\r\n",
        "\r\n",
        "  Output:\r\n",
        "  - labels: shuffled labels of the neutrino interactions.\r\n",
        "  - image_set_1: shuffled images corresponding to the x-z view of the interaction.\r\n",
        "  - image_set_2: shuffled images corresponding to the y-z view of the interaction.\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  zip_data = list(zip(labels, image_set_1, image_set_2))    # zips all the data to be able to shuffle it together \r\n",
        "  np.random.shuffle(zip_data)                               # shuffled the data \r\n",
        "  labels, image_set_1, image_set_2 = zip(*zip_data)         # unzips the data \r\n",
        "\r\n",
        "  return labels, image_set_1, image_set_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv-NDIjT7m1n"
      },
      "source": [
        "The data has to be prepared in order to feed it into the network. As this is a procedure that will have to be done throughout the project, a function will be defined. In this function, the labels and the two input images will be put into arrays. These will then be split into data to train the model and data to test the model. The training data will further be split into training and validation data. Lastly, the data will be normalized so that it is between 0 and 1 pixels and it will be converted to the same data type. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acm4dBm-Lomj"
      },
      "source": [
        "def data (model_input_1, model_input_2, model_labels, train_frac, val_frac):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  This function takes the labels and the two sets of corresponding images as an input and puts them into separate arrays,\r\n",
        "  splits the data into training, testing and validation data sets, normalizes the images to be between 0 and 1 pixels and \r\n",
        "  puts all the data in the same format. It prepares the data to be fed into the neural network. \r\n",
        "\r\n",
        "  Input:\r\n",
        "  - model_labels: labels of the neutrino interactions.\r\n",
        "  - model_input_1: images corresponding to the x-z view of the interaction.\r\n",
        "  - model_input_2: images corresponding to the y-z view of the interaction.\r\n",
        "  - train_frac: fraction to split the data into training and testing data. If 80% is used, 80% will be used for training and 20% for testing. \r\n",
        "  - val_fraction: fraction to split the training data into training and validation data. \r\n",
        "\r\n",
        "  Output:\r\n",
        "  - train_input_1: training data corresponding to the x-z view of the interaction. \r\n",
        "  - test_input_1: testing data corresponding to the x-z view of the interaction. \r\n",
        "  - val_input_1: validation data corresponding to the x-z view of the interaction. \r\n",
        "  - train_input_2: training data corresponding to the y-z view of the interaction. \r\n",
        "  - test_input_2: testing data corresponding to the y-z view of the interaction. \r\n",
        "  - val_input_2: validation data corresponding to the y-z view of the interaction. \r\n",
        "  - train_labels: training labels of the interaction. \r\n",
        "  - val_labels: validation labels of the interaction.  \r\n",
        "  - test_labels: testing labels of the interaction. \r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # Making arrays of all the data \r\n",
        "  model_in_1 = np.array(model_input_1)\r\n",
        "  model_in_2 = np.array(model_input_2)\r\n",
        "  model_lab = np.array(model_labels)\r\n",
        "  \r\n",
        "  # Splitting the data into train and test data\r\n",
        "  tr_input_1, te_input_1 = train_test_split(model_in_1, train_size = train_frac, shuffle = False)\r\n",
        "  tr_input_2, te_input_2 = train_test_split(model_in_2, train_size = train_frac, shuffle = False)\r\n",
        "  tr_labels, te_labels = train_test_split(model_lab, train_size = train_frac, shuffle = False)\r\n",
        "\r\n",
        "  # Splitting the data into training and validation data sets\r\n",
        "  train_input_1, val_input_1 = train_test_split(tr_input_1, train_size = val_frac, shuffle = False)\r\n",
        "  train_input_2, val_input_2 = train_test_split(tr_input_2, train_size = val_frac, shuffle = False)\r\n",
        "  train_labels, val_labels =train_test_split(tr_labels, train_size = val_frac, shuffle = False)\r\n",
        "\r\n",
        "  # Normalizing the images to be between 0 and 1 pixels and converting the arrays to the same data type  \r\n",
        "  train_input_1 = train_input_1.astype('float32') / 255.0\r\n",
        "  val_input_1 = val_input_1.astype('float32') / 255.0\r\n",
        "  test_input_1 = te_input_1.astype('float32') / 255.0\r\n",
        "\r\n",
        "  train_input_2 = train_input_2.astype('float32') / 255.0\r\n",
        "  val_input_2 = val_input_2.astype('float32') / 255.0\r\n",
        "  test_input_2 = te_input_2.astype('float32') / 255.0\r\n",
        "\r\n",
        "  train_labels = train_labels.astype('float32')\r\n",
        "  val_labels = val_labels.astype('float32')\r\n",
        "  test_labels = te_labels.astype('float32')\r\n",
        "\r\n",
        "  return (train_input_1, test_input_1, val_input_1, train_input_2, test_input_2, val_input_2, train_labels, val_labels, test_labels)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SivbQxwKAoRB"
      },
      "source": [
        "Having these definitions we are going to prepare the data. First we will shuffle all the images and labels, then we will expand the dimensions as we need a shape of 4 for the images of the neutrino interactions to feed into the neural network and lastly we will put the data into arrays and split it to obtain training, testing and validation data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAV21Hm_zY4N"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "model_lab, model_in_1, model_in_2 = shuffle_data(model_lab, model_in_1, model_in_2)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "model_in_1 = tf.expand_dims(model_in_1, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "model_in_2 = tf.expand_dims(model_in_2, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1, test_input_1, val_input_1, train_input_2, test_input_2, val_input_2, train_labels, val_labels, test_labels = data(model_in_1, model_in_2, model_lab, 0.8, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd1qmUrz92Qt"
      },
      "source": [
        "<a name=\"CNN\"></a>\r\n",
        "\r\n",
        "## 3.5 Multi-view Convolutional Neural Network\r\n",
        "\r\n",
        "The inputs from the x-y view and the y-z are handled separately in two branches of the network and are then merged in the final few layers of the model, this is called a multi-view CNN. Where the network is learning about one neutrino interaction by “viewing” it from different perspectives. This multi-view CNN model is going to be created using the keras functional API which can handle models with non-linear topology, shared layers, and even multiple inputs or outputs. The architecture of this network, which can be seen in Figure 4, was inspired by VGGNet and ResNet but was adapted to this specific task. \r\n",
        "\r\n",
        "\r\n",
        "The model contains 3 convolutional layers for feature extraction for both the inputs. Convolution1D is usually used for input signals similar to the voice, Convolution2D is used for images and Convolution3D is used for videos. Therefore, Convolution2D is the first hidden layer being used. The second hidden layer is MaxPooling2D, which downsamples the inputs by calculating the maximum value in each patch of every feature map. AveragePooling2D could be used but for computer visions tasks such as this one, MaxPooling2D has been proved to be more effective. Lastly a Dropout layer is used for regularization technique to avoid overfitting. This drops a percentage of data randomly. \r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VMuMoY2HF7d"
      },
      "source": [
        "def create_convolution_layers(input_img, input_shape):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  This function creates a simple Convolutional Neural Network model in keras using the functional API.\r\n",
        "\r\n",
        "  Input:\r\n",
        "  - input_img: image to be fed into the network, either the x-z view of the interaction or the y-z view.\r\n",
        "  - input_shape: shape of the images being fed into the network.\r\n",
        "\r\n",
        "  Output:\r\n",
        "  - model: CNN model  \r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  # releases the global state and helps avoid clutter from other models\r\n",
        "  #keras.backend.clear_session   \r\n",
        "\r\n",
        "  # Conv2D layer is used for images.  \r\n",
        "  model = Conv2D(8, (3, 3),                                                     # Using a filter size of 8, kernel size of (3,3)\r\n",
        "                 activation = \"relu\",                                           # Rectified Linear Unit as activation function\r\n",
        "                 padding='same', input_shape=input_shape[1:])(input_img)        # Keeping the padding 'same' allows to preserve spatial dimension\r\n",
        "  # Max pooling operation for 2D spatial data.\r\n",
        "  model = MaxPooling2D((2, 2),                                                  # Pool size of (2,2)\r\n",
        "                       padding='same')(model)                                   # Keeping the padding 'same' allows to preserve spatial dimension\r\n",
        "  # Regularization technique for the model\r\n",
        "  model = Dropout(0.25)(model)                                                  # 25% of the data is randomly excluded \r\n",
        "  \r\n",
        "  # Conv2D layer is used for images.\r\n",
        "  model = Conv2D(16, (3, 3),                                                    # Using a filter size of 16, kernel size of (3,3)\r\n",
        "                 padding='same')(model)                                         # Keeping the padding 'same' allows to preserve spatial dimension\r\n",
        "  # Max pooling operation for 2D spatial data.\r\n",
        "  model = MaxPooling2D((2, 2),                                                  # Pool size of (2,2)\r\n",
        "                       padding='same')(model)                                   # Keeping the padding 'same' allows to preserve spatial dimension\r\n",
        "  model = Dropout(0.25)(model)                                                  # 25% of the data is randomly excluded \r\n",
        " \r\n",
        "  # Conv2D layer is used for images.\r\n",
        "  model = Conv2D(16, (3, 3),                                                    # Using a filter size of 32, kernel size of (3,3)\r\n",
        "                 padding='same')(model)                                         # Keeping the padding 'same' allows to preserve spatial dimension\r\n",
        "  # Max pooling operation for 2D spatial data.\r\n",
        "  model = MaxPooling2D((2, 2),                                                  # Pool size of (2,2)\r\n",
        "                       padding='same')(model)                                   # Keeping the padding 'same' allows to preserve spatial dimension\r\n",
        "  model = Dropout(0.4)(model)                                                   # 40% of the data is randomly excluded    \r\n",
        " \r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwzWTbv62bmT"
      },
      "source": [
        " The two inputs are merged by a concatenate layer and then go through a Flatten layer that converts the 2D matrix into a vector. It then goes through a Dense layer which connects all the neuron in a layer to the neurons in the next layer, a ReLU activation function and a Dropout layer. At last, it goes through another Dense layer and a sigmoid activation function, which transforms the input into a value between 0.0 and 1.0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCWqLbvPHq99"
      },
      "source": [
        "def concatenating (model_input_1):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  This function creates a simple Convolutional Neural Network model in keras using the functional API for both the views of the \r\n",
        "  neutrino intercations, for the x-y view and the y-z view, and concatenates them. \r\n",
        "\r\n",
        "  Input:\r\n",
        "  - model_input_1: this is the image of the x-z view of the neutrino interaction. It is used to obtain the shape of the model input.\r\n",
        "\r\n",
        "  Output:\r\n",
        "  - model: CNN model of concatenated x-z and y-z views of the neutrino interactions.\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # Creates the CNN model for the x-z view of the neutrino interaction.\r\n",
        "  xz_input = Input(shape=np.shape(model_input_1)[1:])\r\n",
        "  xz_model = create_convolution_layers(xz_input, np.shape(model_input_1)[1:])\r\n",
        "\r\n",
        "  # Creates the CNN model for the y-z view of the neutrino interaction.\r\n",
        "  yz_input = Input(shape=np.shape(model_input_1)[1:])\r\n",
        "  yz_model = create_convolution_layers(yz_input, np.shape(model_input_1)[1:])\r\n",
        "\r\n",
        "  # Concatenates the two models \r\n",
        "  conv = concatenate([xz_model, yz_model])\r\n",
        "\r\n",
        "  # Flattens the concatenated models \r\n",
        "  conv = Flatten()(conv)\r\n",
        "\r\n",
        "  # Dense layers connect all the neurons of one layer to the ones in the next layer \r\n",
        "  dense = Dense(8,                                                              # 64 is the dimensionality of the output space\r\n",
        "                activation = \"relu\")(conv)                                      # Rectified Linear Unit as activation function\r\n",
        "  dense = Dropout(0.5)(dense)                                                   # 50% of the data is randomly excluded                                                   # 50% of the data is randomly excluded \r\n",
        "\r\n",
        "  output = Dense(1,                                                             # 1 is the dimensionality of the output space \r\n",
        "                 activation =\"sigmoid\")(dense)                                  # sigmoid as activation function. \r\n",
        "                                                                                # The input to the function is transformed into a value between 0.0 and 1.0.\r\n",
        " \r\n",
        "  # creates the model using the two model inputs \r\n",
        "  model = Model(inputs = [xz_input, yz_input], outputs = [output])\r\n",
        "\r\n",
        "  # compiles the final model\r\n",
        "  model.compile(loss=tf.keras.losses.binary_crossentropy,                       # using binary crossentropy as a loss function as we are doing a binary classification\r\n",
        "  # adam is used for optimization algorithm for stochastic gradient descent for training deep learning models\r\n",
        "                optimizer='adam',                                               \r\n",
        "                metrics=['accuracy'])                                           # using the accuracy as a metric to evaluate the model \r\n",
        "\r\n",
        "  model.summary()\r\n",
        "\r\n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ6VNtRO2pbZ"
      },
      "source": [
        "Now that we have all the definitions, we can create the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O08njMLq6ayJ"
      },
      "source": [
        "## CREATING THE MODEL FOR MUON NEUTRINO CLASSIFICATION\r\n",
        "\r\n",
        "model = concatenating(model_in_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_uWEayde87j"
      },
      "source": [
        "Now that the model has been created, it can be trained on the training dataset and evaluated on the valuation dataset. Callbacks.EarlyStopping is used to avoid overtraining. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nRQphgWolP4"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history = model.fit(x=[train_input_1,train_input_2],y=train_labels, batch_size=64, # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1,val_input_2],val_labels), \r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9I4Tbt74wgq"
      },
      "source": [
        "Now that the model has been trained, the accuracy and loss is evaluated and plotted. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfv6xn39pMR9"
      },
      "source": [
        "test_loss, test_acc = model.evaluate([test_input_1,test_input_2],  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKNWTpQqxyoC"
      },
      "source": [
        "## PLOTTING THE ACCURACY OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of the muon neutrino classifier')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro_OfpMUkaV1"
      },
      "source": [
        "## PLOTTING THE LOSS OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history.history['loss'], label='loss')\r\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Loss of muon neutrino classifier')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOGnwOFn0POv"
      },
      "source": [
        "## MODEL PREDICTIONS \r\n",
        "\r\n",
        "predictions = model.predict([test_input_1,test_input_2])\r\n",
        "\r\n",
        "plt.hist(predictions,bins=50) # plots the predictions in a histogram "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkWvpPkGSVh2"
      },
      "source": [
        "<a name=\"task2\"></a>\r\n",
        "\r\n",
        "## 4. Task 2: investigating how the variables in the meta data affect the accuracy of the classifier\r\n",
        "\r\n",
        "In this section we are going to investigate how some of the variables in the meta data affects the performance of the classifier. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckNBU7URyZbR"
      },
      "source": [
        "<a name=\"4.1\"></a>\r\n",
        "\r\n",
        "## 4.1 How to define the performance of the classifier?\r\n",
        "\r\n",
        "I am going to test the clasifier to detect electron neutrinos with the original meta data. As there is approximately 2% electron neutrino charged-current events in the meta data available, we would expect the accuracy for this classifier to be lower than the classifier of muon neutrinos. By according to the accuracy paradox, we will obtain a higher accuracy if we use the imbalanced dataset. This means we would obtain false-positives. We are going to test the accuracy paradox to evaluate how important it is to balance the data. \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgWRTQHkBE-o"
      },
      "source": [
        "For this, we firstly need to import the files from which we will obtain the data. This time we will label the electron neutrino charged-current events as 1s and the rest as 0s. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3NXgGcmSW4P"
      },
      "source": [
        "## RETRIEVING THE DATA FILES FOR TASK 2\r\n",
        "\r\n",
        "files_t2 = data_retriever(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I56KxBpyY8i"
      },
      "source": [
        "## CHANGING LABELS FOR A BINARY CLASSIFICATION, 1 REPRESENTS ELECTRON NEUTRINO CC EVENTS AND 0 REPRESENTS EVERYTHING ELSE. \r\n",
        "\r\n",
        "model_lab_elec = []                                                # empty array for the labels of the neutrino interactions, either 0s or 1s\r\n",
        "model_in_1_elec = []                                               # empty array for the x-z view of the neutrino interaction \r\n",
        "model_in_2_elec = []                                               # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for file_name in tqdm(files_t2):\r\n",
        "\r\n",
        "    # opening the file in read only mode \r\n",
        "    df=h5py.File(file_name, 'r')\r\n",
        "    \r\n",
        "    # iterating over the length of cvnmap to obtain the labels and input images for each interaction \r\n",
        "    for i in range(len(df['cvnmap'])):\r\n",
        "      model = df['cvnmap'][i].reshape((2,100,80))                  # reshaping the images \r\n",
        "      model_in_1_elec.append(model[0])                             # apending the x-z view to the corresponding array\r\n",
        "      model_in_2_elec.append(model[1])                             # apending the y-z view to the corresponding array\r\n",
        "\r\n",
        "      if df['neutrino']['interaction'][i] > 3 and df['neutrino']['interaction'][i] <= 7:\r\n",
        "        model_lab_elec.append(int(1))                              # appending a 1 to the labels for electron neutrino CC events \r\n",
        "\r\n",
        "      else:\r\n",
        "        model_lab_elec.append(int(0))                              # appending a 0 to the labels for non electron neutrino CC events\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P50ft-2vDY7l"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "model_lab_elec, model_in_1_elec, model_in_2_elec = shuffle_data(model_lab_elec, model_in_1_elec, model_in_2_elec)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "model_in_1_elec = tf.expand_dims(model_in_1_elec, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "model_in_2_elec = tf.expand_dims(model_in_2_elec, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1_elec, test_input_1_elec, val_input_1_elec, train_input_2_elec, test_input_2_elec, val_input_2_elec, train_labels_elec, val_labels_elec, test_labels_elec = data(model_in_1_elec, model_in_2_elec, model_lab_elec, 0.8, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHCFNMM4EYW6"
      },
      "source": [
        "## CREATING THE MODEL FOR ELECTRON NEUTRINO CLASSIFICATION\r\n",
        "\r\n",
        "model_elec = concatenating(model_in_1_elec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYbBuC6WE2Pu"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history_elec = model_elec.fit(x=[train_input_1_elec,train_input_2_elec],\r\n",
        "                    y=train_labels_elec, batch_size=128,                           # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1_elec,val_input_2_elec],val_labels_elec), \r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFI8XhUyO_wk"
      },
      "source": [
        "test_loss, test_acc = model_elec.evaluate([test_input_1_elec,test_input_2_elec],  test_labels_elec, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyrrll-BPIc3"
      },
      "source": [
        "## PLOTTING THE ACCURACY OF THE MODEL \r\n",
        "\r\n",
        "\r\n",
        "plt.plot(history_elec.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history_elec.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of electron neutrino classifier')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJuq3x043urF"
      },
      "source": [
        "## PLOTTING THE LOSS OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history_elec.history['loss'], label='loss')\r\n",
        "plt.plot(history_elec.history['val_loss'], label = 'val_loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Loss of electron neutrino classifier')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY_TS0hxPUm-"
      },
      "source": [
        "A higher accuracy is obtained for classification of electron neutrino charged-current events, as expected from the accuracy paradox. Although it can be seen from the graph of the accuracy that the model is not really learning. This demonstrated the importance of having a balanced dataset. \r\n",
        "\r\n",
        "To ensure this observation is correct, this classification will be performed on a balanced dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCUd_yOFQSLK"
      },
      "source": [
        "## RETRIEVING THE FILES FOR ELECTRON NEUTRINO CLASSIFICATION \r\n",
        "\r\n",
        "files_t2_2 = np.array(data_retriever(68))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41bwfrTPHFD-"
      },
      "source": [
        "To balance the data for electron neutrino CC events we will need to iterate through significantly more files to obtain the data corresponding to electron neutrinos and very few for the rest. \r\n",
        "\r\n",
        "Here we are using 70 files to obtain the data corresponding to electron neutrinos and 1 files for non-electron neutrino CC events, this represents 1% of the datafiles. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f1E7vHcRnd1"
      },
      "source": [
        "## SPLITTING THE DATA FILES \r\n",
        "\r\n",
        "# using 100% of the files for electron neutrino CC events and 1% for the rest\r\n",
        "files_t2_2_90, files_t2_2_10 = train_test_split(files_t2_2, train_size = 0.99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCSqRGwGIi3M"
      },
      "source": [
        "## LABELS FOR BINARY CLASSIFICATION AND BALANCING THE DATA \r\n",
        "# using 1s to label electron neutrino CC events and 0s to label the rest\r\n",
        "\r\n",
        "# empty arrays\r\n",
        "model_lab_elec_b=[]                                                     # empty array for the labels of the neutrino interactions, either 0s or 1s \r\n",
        "model_in_1_elec_b = []                                                  # empty array for the x-z view of the neutrino interaction\r\n",
        "model_in_2_elec_b = []                                                  # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for file_name in tqdm(files_t2_2):\r\n",
        "\r\n",
        "    # opening the file in read only mode \r\n",
        "    df=h5py.File(file_name, 'r')\r\n",
        "    \r\n",
        "    # iterating over the length of cvnmap to obtain the labels and input images for each interaction \r\n",
        "    for i in range(len(df['cvnmap'])):\r\n",
        "      \r\n",
        "      # if the interaction number is above between 4 and 7 it is an electron neutrino CC event\r\n",
        "      if (df['neutrino']['interaction'][i])>=4 and (df['neutrino']['interaction'][i])<=7: \r\n",
        "\r\n",
        "        model = df['cvnmap'][i].reshape((2,100,80))                     # reshaping the images \r\n",
        "        model_in_1_elec_b.append(model[0])                              # apending the x-z view to the corresponding array\r\n",
        "        model_in_2_elec_b.append(model[1])                              # apending the y-z view to the corresponding array\r\n",
        "        model_lab_elec_b.append(int(1))                                 # appends a 1 to the labels array for electron neutrino CC interactions\r\n",
        "\r\n",
        "      else:\r\n",
        "        pass\r\n",
        "\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for file_name in tqdm(files_t2_2_10):\r\n",
        "\r\n",
        "    # opening the file in read only mode \r\n",
        "    df=h5py.File(file_name, 'r')\r\n",
        "    \r\n",
        "    # iterating over the length of cvnmap to obtain the labels and input images for each interaction \r\n",
        "    for j in range(len(df['cvnmap'])):\r\n",
        "      \r\n",
        "      # if the interaction number is below 3 or above 8 it is not an electron neutrino CC event\r\n",
        "      if (df['neutrino']['interaction'][j])<=3 or (df['neutrino']['interaction'][j])>=8:\r\n",
        "\r\n",
        "        model = df['cvnmap'][j].reshape((2,100,80))                     # reshaping the images \r\n",
        "        model_in_1_elec_b.append(model[0])                              # apending the x-z view to the corresponding array\r\n",
        "        model_in_2_elec_b.append(model[1])                              # apending the y-z view to the corresponding array\r\n",
        "        model_lab_elec_b.append(int(0))                                 # appends a 1 to the labels array for muon neutrino CC interactions\r\n",
        "\r\n",
        "      else:\r\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G19E3r2iJp8z"
      },
      "source": [
        "Now that we have the labels, we should plot it on a histogram to make sure the data is balanced. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhIDUj1W-anK"
      },
      "source": [
        "## HISTOGRAM OF LABELS FOR ELECTRON NEUTRINO CLASSIFICATION \r\n",
        "\r\n",
        "plt.hist(model_lab_elec_b)\r\n",
        "plt.title('Balanced data set for electron neutrino CC events detection')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RawQvWM7J8te"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "model_lab_elec_b, model_in_1_elec_b, model_in_2_elec_b = shuffle_data(model_lab_elec_b, model_in_1_elec_b, model_in_2_elec_b)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "model_in_1_elec_b = tf.expand_dims(model_in_1_elec_b, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "model_in_2_elec_b = tf.expand_dims(model_in_2_elec_b, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1_elec_b, test_input_1_elec_b, val_input_1_elec_b, train_input_2_elec_b, test_input_2_elec_b, val_input_2_elec_b, train_labels_elec_b, val_labels_elec_b, test_labels_elec_b = data(model_in_1_elec_b, model_in_2_elec_b, model_lab_elec_b, 0.8, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhKvRVFwKXSC"
      },
      "source": [
        "## CREATING THE MODEL FOR ELECTRON NEUTRINO CLASSIFICATION\r\n",
        "\r\n",
        "model_elec_b = concatenating(model_in_1_elec_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfdPGVkqKfUw"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history = model_elec_b.fit(x=[train_input_1_elec_b,train_input_2_elec_b],\r\n",
        "                    y=train_labels_elec_b, batch_size=32,                          # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1_elec_b,val_input_2_elec_b],val_labels_elec_b),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeHXkBO1HWfR"
      },
      "source": [
        "test_loss, test_acc = model.evaluate([test_input_1_elec_b,test_input_2_elec_b],  test_labels_elec_b, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSwKIMWXcUUD"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "299ER2xgdemw"
      },
      "source": [
        "It can be seen how the accuracy is reduced once the dataset is balanced. This demonstrates how important it is to balance the data in order to now get false-trues. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUClUSuQcLjt"
      },
      "source": [
        "<a name=\"4.2\"></a>\r\n",
        "\r\n",
        "## 4.2 How well does the classifier perform on QE events vs DIS events?\r\n",
        "\r\n",
        "A QE, quasi-elastic, charged-current events usually only has two track and is therefore a \"clean\" events. On the other hand, DIS, deep inelastic scattering, charged-current events are a a lot more \"messy\" as it can have several tracks and showers. In this section we are going to explore how do these type of events affect the results of the classifier. \r\n",
        "\r\n",
        "We will start by checking how many QE and DIS CC events there were in task 1 and then exploring the other options. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm6CoRL0bc1F"
      },
      "source": [
        "## RETRIEVING THE FILES FOR TASK 4.2\r\n",
        "\r\n",
        "files_t2_3 = np.array(data_retriever(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt8BSzNwx3pw"
      },
      "source": [
        "## CHECKING HOW MANY QE AND DIS EVENTS ARE THERE IN THE DATASET\r\n",
        "\r\n",
        "QE_counter = 0                                                  # counter to keep track of how many QE events there are \r\n",
        "DIS_counter = 0                                                 # counter to keep track of how many DIS events there are \r\n",
        "total_events = 0                                                # counter to keep track of the total number of interactions taking place\r\n",
        "\r\n",
        "# iterating over the loaded data files to obtain the number of each type of events \r\n",
        "for file_name in tqdm(files_t2_3):\r\n",
        "\r\n",
        "  # opening the file in read mode only \r\n",
        "  df=h5py.File(file_name, 'r')\r\n",
        "\r\n",
        "  # total number of events in that file \r\n",
        "  tot = len(df['neutrino']['interaction'])\r\n",
        "\r\n",
        "  # adds the number of events of that file to the global total number of events \r\n",
        "  total_events = total_events + tot\r\n",
        "  \r\n",
        "  # iterating over the length of the images of neutrino interactions in the data file\r\n",
        "  for i in range(len(df['cvnmap'])):  \r\n",
        "\r\n",
        "    # if the neutrino interaction is equal to 0, 4 or 8 it is QE CC events\r\n",
        "    if (df['neutrino']['interaction'][i]) == 0 or (df['neutrino']['interaction'][i]) == 4 or (df['neutrino']['interaction'][i]) == 8: \r\n",
        "\r\n",
        "      QE_counter = QE_counter + 1 \r\n",
        "    \r\n",
        "    # if the neutrino interaction is equal to 2, 6 or 19 it is DIS CC events\r\n",
        "    elif (df['neutrino']['interaction'][i]) == 2 or (df['neutrino']['interaction'][i]) == 6 or (df['neutrino']['interaction'][i]) == 10:\r\n",
        "      \r\n",
        "      DIS_counter = DIS_counter + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tDND49kzAex"
      },
      "source": [
        "## CALCULATING THE PERCENTAGE OF QE AND DIS CC EVENTS IN THE DATASET \r\n",
        "\r\n",
        "percent_DIS = \"{:.2f}\".format((DIS_counter / total_events)*100)                 # calculates the percentage of DIS CC events in the data \r\n",
        "percent_QE = \"{:.2f}\".format((QE_counter / total_events)*100)                   # calculates the percentage of QE CC events in the data \r\n",
        "\r\n",
        "# prints the number of QE and DIS events and their corresponding percentages\r\n",
        "print (\"Number of files used:\",len(files_t2_3), \"\\nTotal number of events:\", total_events, \"\\nNumber of CC DIS events:\", DIS_counter, \r\n",
        "       \". This represents a \", percent_DIS, \"% of the total events\", \"\\nNumber of CC QE events: \", QE_counter, \r\n",
        "       \". This represents a\", percent_QE,\"% of the total events\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gszW9gcpgQhL"
      },
      "source": [
        "From the results above we can see that for 20 files there is a higher percentage of CC DIS events compared to QE events. There is approximately 54% CC DIS events in the file while there is approximately 12% CC QE events. It was found that these percentage were approximately held for all the files. Therefore, the accuracy obtained for the classifier in task 1 is for a dataset with a higher number of CC DIS events compared to CC QE events. Which means the classifier has been learning more on \"messier\" events. As this is an image classification task I would expect the classifier to perform better on CC QE, \"neater\", events. We are going to test this in this section. We will first test the performance of the classifier in a dataset with equal number of CC QE and CC DIS events and then on a dataset with a higher number of CC QE events. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaAsEO3r7nnG"
      },
      "source": [
        "### Performance for equal number of CC QE and CC DIS events \r\n",
        "\r\n",
        "The first thing we need to do is balance the labels and the CC QE and CC DIS events. For this we will need to iterate on different number of files. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfBXwnLF-5g5"
      },
      "source": [
        "## SPLITTING THE DATA TO BALANCE THE LABELS AND CC DIS AND CC QE EVENTS \r\n",
        "\r\n",
        "files_80, files_20 = train_test_split(files_t2_3, train_size = 0.7, shuffle = False)\r\n",
        "files_80_2, files_20_2 = train_test_split(files_20, train_size = 0.7, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1q6p3Sg8o65"
      },
      "source": [
        "## LABELS FOR BINARY CLASSIFICATION OF MUON NEUTRINO CC EVENTS \r\n",
        "## AND BALANCING THE CC QE AND CC DIS EVENTS IN MUON NEUTRINO INTERACTIONS\r\n",
        "\r\n",
        "model_in_1_bal_even = []                                                # empty array for the x-z view of the neutrino interaction\r\n",
        "model_in_2_bal_even = []                                                # empty array for the y-z view of the neutrino interaction\r\n",
        "model_lab_bal_even = []                                                 # empty array for the labels of the neutrino interactions, either 0s or 1s \r\n",
        "QE_counter = 0                                                          # counter to keep track of how many QE events there are \r\n",
        "DIS_counter = 0                                                         # counter to keep track of how many DIS events there are \r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for f_name in tqdm(files_t2_3):                                         # using 20 files \r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(f_name, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of cvnmap to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['cvnmap'])):\r\n",
        "\r\n",
        "    # if the neutrino interaction number is above 3 it is a non-muon neutrino interaction\r\n",
        "    if df['neutrino']['interaction'][i] > 3:\r\n",
        "\r\n",
        "        model = (df['cvnmap'][i]).reshape((2,100,80))                   # reshaping the images \r\n",
        "        model_in_1_bal_even.append(model[0])                            # apending the x-z view to the corresponding array\r\n",
        "        model_in_2_bal_even.append(model[1])                            # apending the y-z view to the corresponding array\r\n",
        "        model_lab_bal_even.append(int(0))                               # assigns a 0 to non muon neutrino CC events  \r\n",
        "\r\n",
        "    else:\r\n",
        "      pass \r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for f_name in tqdm(files_20):                                           # using 4 files \r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(f_name, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of cvnmap to obtain the labels and input images for each interaction \r\n",
        "  for j in range(len(df['cvnmap'])):\r\n",
        "\r\n",
        "    # if the interaction number is 0 it is a muon neutrino CC QE event \r\n",
        "    if df['neutrino']['interaction'][j] == 0:\r\n",
        "\r\n",
        "      model = (df['cvnmap'][j]).reshape((2,100,80))                       # reshaping the images \r\n",
        "      model_in_1_bal_even.append(model[0])                                # apending the x-z view to the corresponding array\r\n",
        "      model_in_2_bal_even.append(model[1])                                # apending the y-z view to the corresponding array\r\n",
        "      model_lab_bal_even.append(int(1))                                   # assigns 1 to muon neutrino CC events \r\n",
        "\r\n",
        "      QE_counter = QE_counter + 1\r\n",
        "\r\n",
        "    else:\r\n",
        "      pass \r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for f_name in tqdm(files_20_2):                                           # using 1 files \r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(f_name, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of cvnmap to obtain the labels and input images for each interaction\r\n",
        "  for z in range(len(df['cvnmap'])):\r\n",
        "\r\n",
        "    # if the neutrino interaction number is equal or below 3 it is a muon neutrino CC event\r\n",
        "    if df['neutrino']['interaction'][z] <= 3:\r\n",
        "      \r\n",
        "      model = (df['cvnmap'][z]).reshape((2,100,80))                       # reshaping the images \r\n",
        "      model_in_1_bal_even.append(model[0])                                # apending the x-z view to the corresponding array\r\n",
        "      model_in_2_bal_even.append(model[1])                                # apending the y-z view to the corresponding array\r\n",
        "      model_lab_bal_even.append(int(1))                                   # assigns 1 to muon neutrino CC events \r\n",
        "\r\n",
        "      # is the neutrino interaction number is 0 it is a QE event        \r\n",
        "      if (df['neutrino']['interaction'][z]) == 0: \r\n",
        "        QE_counter = QE_counter + 1 \r\n",
        "\r\n",
        "      # is the neutrino interaction number is 0 it is a DIS event    \r\n",
        "      elif (df['neutrino']['interaction'][z]) == 2:\r\n",
        "      \r\n",
        "        DIS_counter = DIS_counter + 1\r\n",
        "\r\n",
        "    else:\r\n",
        "      pass "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsQrYV03Mn7J"
      },
      "source": [
        "## CHECKING IF QE CC EVENTS AND DIS CC EVENTS ARE BALANCED\r\n",
        "\r\n",
        "print(\"Muon neutrino CC QE events:\", QE_counter)\r\n",
        "print(\"Muon neutrino CC DIS events:\", DIS_counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-AwxfUu-_tf"
      },
      "source": [
        "## CHECKING IF THE LABELS ARE BALANCED \r\n",
        "\r\n",
        "plt.hist(model_lab_bal_even)\r\n",
        "plt.title('Labels for muon neutrino classification on a QE and DIS balanced dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc_dzinJnFxH"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "model_lab_bal_even, model_in_1_bal_even, model_in_2_bal_even = shuffle_data(model_lab_bal_even, model_in_1_bal_even, model_in_2_bal_even)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "model_in_1_bal_even = tf.expand_dims(model_in_1_bal_even, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "model_in_2_bal_even = tf.expand_dims(model_in_2_bal_even, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1, test_input_1, val_input_1, train_input_2, test_input_2, val_input_2, train_labels, val_labels, test_labels = data(model_in_1_bal_even, model_in_2_bal_even, model_lab_bal_even,0.8,0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLE_44Z1TM3t"
      },
      "source": [
        "## CREATING THE MODEL FOR MUON NEUTRINO CLASSIFICATION\r\n",
        "\r\n",
        "model = concatenating(model_in_1_bal_even)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U5QAPWFnaGO"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history = model.fit(x=[train_input_1,train_input_2],\r\n",
        "                    y=train_labels, batch_size=64,                                 # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1,val_input_2],val_labels),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwi2_i5yT64E"
      },
      "source": [
        "## EVALUATING THE ACCURACY AND LOSS OF THE MODEL \r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate([test_input_1,test_input_2],  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQA38AAKUBGb"
      },
      "source": [
        "## PLOTTING THE ACCURACY \r\n",
        "\r\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of muon neutrino classifier for \\n a dataset with equal QE and DIS events')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg_1h-AXn0-q"
      },
      "source": [
        "## PLOTTING THE LOSS \r\n",
        "\r\n",
        "plt.plot(history.history['loss'], label='loss')\r\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Loss of muon neutrino classifier for \\n a dataset with equal QE and DIS events')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH81q6_EoBgj"
      },
      "source": [
        "It can clearly be seen that the accuracy increase when the classifier operates on a dataset with equal number of CC QE and CC DIS events, as expected. \r\n",
        "\r\n",
        "We are now going to test the classifier on a dataset of more CC QE than CC DIS events, it is expected that the accuracy should increase even more having \"clean\" events. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta1x5WmHeff7"
      },
      "source": [
        "### PERFORMANCE OF THE CLASSIFIER ON DATASET WITH ONLY MUON NEUTRINO CC QE EVENTS\r\n",
        "\r\n",
        "The muon neutrino classifier is going to be tested on a dataset which only has CC QE events. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PZEp4K4fKS_"
      },
      "source": [
        "files_80, files_20 = train_test_split(files_t2_3, train_size = 0.8, shuffle = False)\r\n",
        "files_80_2, files_20_2 = train_test_split(files_20, train_size = 0.7, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaTedwPaefJ_"
      },
      "source": [
        "## LABELS FOR BINARY CLASSIFICATION AND BALANCING THE DATA \r\n",
        "# using 1s to label electron neutrino CC events and 0s to label the rest\r\n",
        "# only using CC QE events \r\n",
        "\r\n",
        "model_in_1_qe = []                                                          # empty array for the labels of the neutrino interactions, either 0s or 1s \r\n",
        "model_in_2_qe = []                                                          # empty array for the x-z view of the neutrino interaction\r\n",
        "model_lab_qe = []                                                           # empty array for the y-z view of the neutrino interaction\r\n",
        "QE_counter_qe = 0                                                           # counter to keep track of how many CC QE events there are \r\n",
        "DIS_counter_qe = 0                                                          # counter to keep track of how many CC DIS events there are \r\n",
        "\r\n",
        "# iterating over the loaded data files to obtain the number of each type of events \r\n",
        "for f_name in tqdm(files_t2_3):                                             # using 20 files \r\n",
        "\r\n",
        "  # opening the file in read mode only \r\n",
        "  df=h5py.File(f_name, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions in the data file\r\n",
        "  for i in range(len(df['cvnmap'])):\r\n",
        "\r\n",
        "    # if the neutrino interaction number is higher than 3, it is a non-muon neutrino event\r\n",
        "    if df['neutrino']['interaction'][i] > 3:\r\n",
        "      \r\n",
        "        model = (df['cvnmap'][i]).reshape((2,100,80))                       # reshaping the images \r\n",
        "        model_in_1_qe.append(model[0])                                      # apending the x-z view to the corresponding array\r\n",
        "        model_in_2_qe.append(model[1])                                      # apending the y-z view to the corresponding array\r\n",
        "        model_lab_qe.append(int(0))                                         # assigns a 0 to non muon neutrino CC events  \r\n",
        "        \r\n",
        "    else:\r\n",
        "      pass \r\n",
        "\r\n",
        "# iterating over the loaded data files to obtain the number of each type of events \r\n",
        "for f_name in tqdm(files_t2_3):                                             # using 4 files \r\n",
        "\r\n",
        "  # opening the file in read mode only \r\n",
        "  df=h5py.File(f_name, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of images in the data file\r\n",
        "  for j in range(len(df['cvnmap'])):\r\n",
        "\r\n",
        "    # is the neutrino interaction corresponds to 0 it is a muon neutrino CC QE event\r\n",
        "    if df['neutrino']['interaction'][j] == 0:\r\n",
        "\r\n",
        "      model = (df['cvnmap'][j]).reshape((2,100,80))                       # reshaping the images\r\n",
        "      model_in_1_qe.append(model[0])                                      # apending the x-z view to the corresponding array\r\n",
        "      model_in_2_qe.append(model[1])                                      # apending the y-z view to the corresponding array\r\n",
        "      model_lab_qe.append(int(1))                                         # assigns 1 to muon neutrino CC events \r\n",
        "\r\n",
        "      QE_counter_qe = QE_counter_qe + 1\r\n",
        "\r\n",
        "    else:\r\n",
        "      pass "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzapftbuJiCM"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "model_lab_qe, model_in_1_qe, model_in_2_qe = shuffle_data(model_lab_qe, model_in_1_qe, model_in_2_qe)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "model_in_1_qe = tf.expand_dims(model_in_1_qe, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "model_in_2_qe = tf.expand_dims(model_in_2_qe, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1_qe, test_input_1_qe, val_input_1_qe, train_input_2_qe, test_input_2_qe, val_input_2_qe, train_labels_qe, val_labels_qe, test_labels_qe = data(model_in_1_qe, model_in_2_qe, model_lab_qe, 0.8, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnzH5pEVg5GD"
      },
      "source": [
        "## PLOTTING A HISTOGRAM OF THE LABELS TO CHECK IF THEY ARE BALANCED \r\n",
        "\r\n",
        "plt.hist(model_lab_qe)\r\n",
        "plt.title('Labels for muon neutrino classification with a dataset of more CC QE events')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWVXKbgzKGI_"
      },
      "source": [
        "## CREATING THE MODEL FOR ELECTRON NEUTRINO CLASSIFICATION\r\n",
        "\r\n",
        "model = concatenating(model_in_1_qe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah2dK7spKNJV"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history_elec = model.fit(x=[train_input_1_qe,train_input_2_qe],\r\n",
        "                    y=train_labels_qe, batch_size=64,                              # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1_qe,val_input_2_qe],val_labels_qe),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36khr_Ueorej"
      },
      "source": [
        "## EVALUATING THE ACCURACY AND LOSS OF THE MODEL \r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate([test_input_1_qe,test_input_2_qe],  test_labels_qe, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FHokxbio4tn"
      },
      "source": [
        "## PLOTTING THE ACCURACY OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history_elec.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history_elec.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of muon neutrino classifier operating \\n on a dataset of QE events')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWSvZcWuFgMd"
      },
      "source": [
        "## PLOTTING THE LOSS OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history_elec.history['loss'], label='loss')\r\n",
        "plt.plot(history_elec.history['val_loss'], label = 'val_loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Loss of muon neutrino classifier operating \\n on a dataset of QE events')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Mz9M2HxTNe"
      },
      "source": [
        "## OBSERVATIONS\r\n",
        "\r\n",
        "The highest accuracy for the classifier was obtained for a dataset with only CC QE events, which is what was predicted as these are less \"messy\" events. \r\n",
        "\r\n",
        "A good performance was achieved for a dataset of balanced CC QE and CC DIS events.\r\n",
        "\r\n",
        "Lowest performance for a dataset of predominantly CC DIS events, which is what was used for task 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjt28x1cDOh"
      },
      "source": [
        "<a name=\"4.3\"></a>\r\n",
        "\r\n",
        "## 4.3 How well does the classifier perform on low energy neutrinos vs high energy neutrinos?\r\n",
        "\r\n",
        "In this section we will explore how does the performance of the model change whehn it is operating on high energy neutrino and when it is operating on low energy neutrinos. The thershold for high energy is set at 3.5 MeV, obtained from https://iopscience.iop.org/article/10.1088/1742-6596/718/6/062052/pdf.\r\n",
        "\r\n",
        "From intuition, I am not expecting the accuracies to vary drastically as this is an image classification task and therefore what matters is what is seen on the image. The energy of the neutrinos should not have a significant impact on the clarity of the image.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB-6JoTLPYj8"
      },
      "source": [
        "## Testing performance only on high energy neutrinos\r\n",
        "\r\n",
        "We will start by testing the performance for a dataset that only contains high energy neutrinos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWAPcK-NywwK"
      },
      "source": [
        "## RETRIEVING THE FILES FOR THIS SECTION \r\n",
        "\r\n",
        "files_t2_4=data_retriever(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KsjDntnSTOa"
      },
      "source": [
        "## SPLITTING THE FILES TO BE ABLE TO BALANCE THE LABELS \r\n",
        "\r\n",
        "files_80, files_20 = train_test_split(files_t2_4, train_size = 0.9, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nmQ6-67QJ2e"
      },
      "source": [
        "## SETTING THE THRESHOLD FOR HIGH/LOW ENERGY NEUTRINO\r\n",
        "\r\n",
        "threshold = 3.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGcuYRytO38G"
      },
      "source": [
        "high_e_labels=[]                                                           # empty array to store the labels, 1 for muon neutrino events and 0 for the rest \r\n",
        "high_e_input_1=[]                                                          # empty array for the x-z view of the neutrino interaction\r\n",
        "high_e_input_2=[]                                                          # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "# iterating over the loaded data files to obtain the number of each type of events \r\n",
        "for filename in tqdm(files_t2_4):\r\n",
        "\r\n",
        "  # opening the file in read mode only\r\n",
        "  df=df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions in the data file\r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    # only classifying those neutrino with energy above the threshold \r\n",
        "    if (df['neutrino']['nuenergy'][i]) > threshold:                \r\n",
        "\r\n",
        "      # if the neutrino interaction number is above 3 it is a non-muon neutrino CC event\r\n",
        "      if (df['neutrino']['interaction'][i]) > 3: \r\n",
        "        model = (df['cvnmap'][i]).reshape((2,100,80))                     # reshaping the images \r\n",
        "        high_e_input_1.append(model[0])                                   # apending the x-z view to the corresponding array\r\n",
        "        high_e_input_2.append(model[1])                                   # apending the y-z view to the corresponding array\r\n",
        "        high_e_labels.append(int(0))                                      # 0 for non muon neutrino CC events \r\n",
        "\r\n",
        "      else:\r\n",
        "        pass\r\n",
        "\r\n",
        "# iterating over the loaded data files to obtain the number of each type of events \r\n",
        "for filename in tqdm(files_20):\r\n",
        "\r\n",
        "  # opening the file in read mode only\r\n",
        "  df=df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions in the data file\r\n",
        "  for j in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    # only classifying those neutrino with energy above the threshold \r\n",
        "    if (df['neutrino']['nuenergy'][j]) > threshold: \r\n",
        "\r\n",
        "      # if the neutrino interaction number is below or equal to 3 it is a muon neutrino CC event\r\n",
        "      if (df['neutrino']['interaction'][j]) <= 3: \r\n",
        "\r\n",
        "        model = (df['cvnmap'][j]).reshape((2,100,80))                     # reshaping the images \r\n",
        "        high_e_input_1.append(model[0])                                   # apending the x-z view to the corresponding array\r\n",
        "        high_e_input_2.append(model[1])                                   # apending the y-z view to the corresponding array\r\n",
        "        high_e_labels.append(int(1))                                      # 1 for non muon neutrino CC events \r\n",
        "\r\n",
        "      else:\r\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-tvlihMRjLH"
      },
      "source": [
        "## CHECKING IF THE LABELS ARE BALANCED \r\n",
        "\r\n",
        "plt.hist(high_e_labels)\r\n",
        "plt.title('Labels for muon neutrino classifier for a dataset of high energy neutrinos')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1NV4gYiPSJO"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "high_e_labels, high_e_input_1, high_e_input_2 = shuffle_data(high_e_labels, high_e_input_1, high_e_input_2)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "high_e_input_1 = tf.expand_dims(high_e_input_1, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "high_e_input_2 = tf.expand_dims(high_e_input_2, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1, test_input_1, val_input_1, train_input_2, test_input_2, val_input_2, train_labels, val_labels, test_labels = data(high_e_input_1, high_e_input_2, high_e_labels, 0.8, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA09tBa7Pi-e"
      },
      "source": [
        "## CREATING THE MODEL FOR ELECTRON NEUTRINO CLASSIFICATION\r\n",
        "\r\n",
        "model = concatenating(high_e_input_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSSUWjmPP5cU"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history = model.fit(x=[train_input_1,train_input_2],\r\n",
        "                    y=train_labels, batch_size=64,                                 # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1,val_input_2],val_labels),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD6nmDzHV-ka"
      },
      "source": [
        "## EVALUATING THE ACCURACY AND LOSS OF THE MODEL \r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate([test_input_1,test_input_2],  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNcNbCKGWFN-"
      },
      "source": [
        "## PLOTTING THE ACCURACY OF THE MODEL\r\n",
        "\r\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of muon neutrino classifier operating \\n on a dataset with high energy neutrinos')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWu5GiKiHkoj"
      },
      "source": [
        "## PLOTTING THE LOSS OF THE MODEL\r\n",
        "\r\n",
        "plt.plot(history.history['loss'], label='loss')\r\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Loss of muon neutrino classifier operating \\n on a dataset with high energy neutrinos')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrvAa0xKWPlr"
      },
      "source": [
        "## Testing performance only on low energy neutrinos\r\n",
        "\r\n",
        "Now we are going to test the performance of the classifier on a dataset that only contains low energy neutrinos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-UkSo5OXeS_"
      },
      "source": [
        "## RETRIEVING THE NECESSARY FILES FOR THIS TASK \r\n",
        "\r\n",
        "files_t2_6=data_retriever(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-EPnz2IW4lq"
      },
      "source": [
        "## SPLITTING THE DATA \r\n",
        "\r\n",
        "files_80_2, files_20_2 = train_test_split(files_t2_6, train_size = 0.9, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hutfPOn3Qpg-"
      },
      "source": [
        "threshold = 3.5\r\n",
        "low_e_labels=[]                                                           # empty array to store the labels, 1 for muon neutrino events and 0 for the rest \r\n",
        "low_e_input_1=[]                                                          # empty array for the x-z view of the neutrino interaction\r\n",
        "low_e_input_2=[]                                                          # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "# iterating over the loaded data files to obtain the number of each type of events \r\n",
        "for filename in tqdm(files_t2_6):\r\n",
        "\r\n",
        "  # opening the file in read mode only\r\n",
        "  df=df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions in the data file\r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    # only classifying those neutrino with energy below the threshold \r\n",
        "    if (df['neutrino']['nuenergy'][i]) < threshold:                \r\n",
        "\r\n",
        "      # if the neutrino interaction number is above 3 it is a non-muon neutrino CC event\r\n",
        "      if (df['neutrino']['interaction'][i]) > 3: \r\n",
        "        model = (df['cvnmap'][i]).reshape((2,100,80))                    # reshaping the images \r\n",
        "        low_e_input_1.append(model[0])                                   # apending the x-z view to the corresponding array\r\n",
        "        low_e_input_2.append(model[1])                                   # apending the y-z view to the corresponding array\r\n",
        "        low_e_labels.append(int(0))                                      # 0 for non muon neutrino CC events \r\n",
        "\r\n",
        "      else:\r\n",
        "        pass\r\n",
        "\r\n",
        "# iterating over the loaded data files to obtain the number of each type of events \r\n",
        "for filename in tqdm(files_20_2):\r\n",
        "\r\n",
        "  # opening the file in read mode only\r\n",
        "  df=df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions in the data file\r\n",
        "  for j in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    # only classifying those neutrino with energy below the threshold \r\n",
        "    if (df['neutrino']['nuenergy'][j]) < threshold: \r\n",
        "\r\n",
        "      # if the neutrino interaction number is below or equal to 3 it is a muon neutrino CC event\r\n",
        "      if (df['neutrino']['interaction'][j]) <= 3: \r\n",
        "\r\n",
        "        model = (df['cvnmap'][j]).reshape((2,100,80))                    # reshaping the images \r\n",
        "        low_e_input_1.append(model[0])                                   # apending the x-z view to the corresponding array\r\n",
        "        low_e_input_2.append(model[1])                                   # apending the y-z view to the corresponding array\r\n",
        "        low_e_labels.append(int(1))                                      # 1 for non muon neutrino CC events \r\n",
        "\r\n",
        "      else:\r\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B15sx0xVWbl1"
      },
      "source": [
        "## PLOTTING THE LABELS TO CHECK IF IT IS BALANCED\r\n",
        "\r\n",
        "plt.hist(low_e_labels)\r\n",
        "plt.title('Labels for muon neutrino classification performing on a dataset of low energy neutrinos')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiyBUVqTRVuE"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "low_e_labels, low_e_input_1, low_e_input_2 = shuffle_data(low_e_labels, low_e_input_1, low_e_input_2)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "low_e_input_1 = tf.expand_dims(low_e_input_1, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "low_e_input_2 = tf.expand_dims(low_e_input_2, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1, test_input_1, val_input_1, train_input_2, test_input_2, val_input_2, train_labels, val_labels, test_labels = data(low_e_input_1, low_e_input_2, low_e_labels, 0.8, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoCLNSAtRm7O"
      },
      "source": [
        "## CREATING THE MODEL FOR ELECTRON NEUTRINO CLASSIFICATION\r\n",
        "\r\n",
        "model = concatenating(low_e_input_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omcQitusR7UK"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history = model.fit(x=[train_input_1,train_input_2],\r\n",
        "                    y=train_labels, batch_size=64,                                 # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1,val_input_2],val_labels),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bos4NhNGbkgA"
      },
      "source": [
        "## EVALUATING THE ACCURACY AND LOSS OF THE MODEL \r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate([test_input_1,test_input_2],  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9TuW-e0bqFR"
      },
      "source": [
        "## PLOTTING THE ACCURACY OF THE MODEL\r\n",
        "\r\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of muon neutrino classifier operating \\n on a dataset of low energy neutrinos')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HClINSBWKPuZ"
      },
      "source": [
        "## PLOTTING THE LOSS OF THE MODEL\r\n",
        "\r\n",
        "plt.plot(history.history['loss'], label='loss')\r\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Loss of muon neutrino classifier operating \\n on a dataset of low energy neutrinos')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geggoy8Qcp-0"
      },
      "source": [
        "## Observations:\r\n",
        "\r\n",
        "The accuracy didn't change significantly for a dataset containing more high energy neutrinos or the dataset containing more low energy neutrinos. This verifies our initial expectations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZkmJ9_kdD49"
      },
      "source": [
        "<a name=\"4.4\"></a>\r\n",
        "\r\n",
        "## 4.4 How well does the classifier perform on low energy muons vs high energy muons?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-m8X4m0dRef"
      },
      "source": [
        "We are now going to perform a similar task as above but in this case with high energy muons and low energy muons. I will start by evaluating how many high energy and low energy muons there are in the original dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4kiUn6tdF2e"
      },
      "source": [
        "files_t2_7=data_retriever(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-fZWv3cOD1I"
      },
      "source": [
        "threshold = 3.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7cHzGhIdyTK"
      },
      "source": [
        "## Counting how many low energy and high energy muons there are in the dataset\r\n",
        "\r\n",
        "low_e_muon = 0                                                    # counter for low energy muon\r\n",
        "high_e_muon = 0                                                   # counter for high energy muon \r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_t2_7):\r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        " \r\n",
        "  # iterating over the length of the neutrino interactions \r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    if (df['neutrino']['interaction'][i]) <=3:                    # interactions below or equal 3 are muon neutrino CC events\r\n",
        "\r\n",
        "      if (df['neutrino']['nuenergy'][i]) > threshold:\r\n",
        "        high_e_muon = high_e_muon + 1 \r\n",
        "\r\n",
        "      else:\r\n",
        "        low_e_muon = low_e_muon + 1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo1z5BcUhpIJ"
      },
      "source": [
        "## PRINTING THE NUMBER OF HIGH AND LOW ENERGY MUON EVENTS AND THEIR CORRESPONDING PERCENTAGES\r\n",
        "\r\n",
        "print(\"Number of high energy muon events:\", high_e_muon)\r\n",
        "print(\"Number of low energy muon events:\", low_e_muon)\r\n",
        "\r\n",
        "print(\"Percentage of high energy muons in\", len(files_t2_7), \"files:\", \"{:.2f}\".format(high_e_muon / (high_e_muon + low_e_muon)*100), \"%\")\r\n",
        "print(\"Percentage of low energy neutrinos in\", len(files_t2_7), \"files: \" \"{:.2f}\".format(low_e_muon / (high_e_muon + low_e_muon)*100), \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfp7VTmbiGHb"
      },
      "source": [
        "## Observations:\r\n",
        "\r\n",
        "There are more high energy muons than low energy muons in the original datasets, which was used for the classifier in task 1. \r\n",
        "\r\n",
        "Percentage of high energy muons in 10 files: 64.75 %\r\n",
        "\r\n",
        "Percentage of low energy neutrinos in 10 files: 35.25 %\r\n",
        "\r\n",
        "The classifier is going to be tested on high energy muons and then on low energy muons although no significant change in accuracy is expected, as above. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4-xFkeqU3If"
      },
      "source": [
        "### Performance on high energy muons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSPtHoJ_j3oP"
      },
      "source": [
        "## RETRIEVING THE FILES FOR THIS TASK \r\n",
        "\r\n",
        "files_80_3, files_20_3 = train_test_split(files_t2_7, train_size = 0.8, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyk24Ik2iv4P"
      },
      "source": [
        "## LABELS FOR BINARY CLASSIFICATION FOR MUON NEUTRINO CLASSIFICATION\r\n",
        "## BEING PERFORMED ON A DATASET OF HIGH ENERGY MUONS \r\n",
        "## BALANCING OUT THE MUON NEUTRINO CC EVENTS AND NON-MUON NEUTRINO CC EVENTS \r\n",
        "\r\n",
        "high_e_muons_labels = []                                              # empty array for the labels of the neutrino interactions, either 0s or 1s \r\n",
        "high_e_muons_input_1 = []                                             # empty array for the x-z view of the neutrino interaction\r\n",
        "high_e_muons_input_2 = []                                             # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_t2_7):\r\n",
        "\r\n",
        "  # opening the file in read only mode \r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    if (df['neutrino']['interaction'][i]) > 3:                        # interactions below or equal 3 are muon neutrino CC events\r\n",
        "\r\n",
        "        model = (df['cvnmap'][i]).reshape((2,100,80))                 # reshaping the images \r\n",
        "        high_e_muons_input_1.append(model[0])                         # apending the x-z view to the corresponding array\r\n",
        "        high_e_muons_input_2.append(model[1])                         # apending the y-z view to the corresponding array\r\n",
        "        high_e_muons_labels.append(int(0))                            # 0 for non muon neutrino CC events \r\n",
        "\r\n",
        "    else:\r\n",
        "      pass\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_20_3):\r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    if (df['neutrino']['interaction'][i]) <=3:                        # interactions below or equal 3 are muon neutrino CC events\r\n",
        "\r\n",
        "      # classifying muons with energy above the threshold \r\n",
        "      if (df['neutrino']['nuenergy'][i]) > threshold:\r\n",
        "\r\n",
        "        model = (df['cvnmap'][i]).reshape((2,100,80))                 # reshaping the images \r\n",
        "        high_e_muons_input_1.append(model[0])                         # apending the x-z view to the corresponding array\r\n",
        "        high_e_muons_input_2.append(model[1])                         # apending the y-z view to the corresponding array\r\n",
        "        high_e_muons_labels.append(int(1))                            # 1 for muon neutrino CC events \r\n",
        "\r\n",
        "      else:\r\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20gciMT4lAvU"
      },
      "source": [
        "## PLOTTING THE LABELS TO CHECK IF THEY ARE BALANCED \r\n",
        "\r\n",
        "plt.hist(high_e_muons_labels)\r\n",
        "plt.title('Labels for muon neutrino classification on a high energy muon dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfGr07X4Wgjo"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "high_e_muons_labels, high_e_muons_input_1, high_e_muons_input_2 = shuffle_data(high_e_muons_labels, high_e_muons_input_1, high_e_muons_input_2)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "high_e_muons_input_1 = tf.expand_dims(high_e_muons_input_1, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "high_e_muons_input_2 = tf.expand_dims(high_e_muons_input_2, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1, test_input_1, val_input_1, train_input_2, test_input_2, val_input_2, train_labels, val_labels, test_labels = data(high_e_muons_input_1, high_e_muons_input_2, high_e_muons_labels, 0.8, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPf9PpfJW5AJ"
      },
      "source": [
        "## CREATING THE MODEL FOR ELECTRON NEUTRINO CLASSIFICATION\r\n",
        "\r\n",
        "model = concatenating(high_e_muons_input_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIna-P_YXDSR"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history = model.fit(x=[train_input_1,train_input_2],\r\n",
        "                    y=train_labels, batch_size=64,                                 # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1,val_input_2],val_labels),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIknhxzsoWmr"
      },
      "source": [
        "## EVALUATING THE ACCURACY AND LOSS OF THE MODEL \r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate([test_input_1,test_input_2],  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsFD_k-Iofq9"
      },
      "source": [
        "## PLOTTING THE ACCURACY OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of muon neutrino classifier operating \\n on a dataset of high energy muons')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z1K0UyKP6vX"
      },
      "source": [
        "## PLOTTING THE LOSS OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history.history['loss'], label='loss')\r\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Loss of muon neutrino classifier operating \\n on a dataset of high energy muons')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WROYWMYNomMo"
      },
      "source": [
        "## Testing the classifier for low energy muons \r\n",
        "\r\n",
        "We are now going to repeat the same procedure but for low energy muons instead. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV3XskQNpfMO"
      },
      "source": [
        "## RETRIEVING THE FILES FOR THIS TASK \r\n",
        "\r\n",
        "files_t2_8=data_retriever(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0AeQGZrpqnE"
      },
      "source": [
        "## SPLITTING THE IMPORTED FILES \r\n",
        "\r\n",
        "files_80_4, files_20_4 = train_test_split(files_t2_8, train_size = 0.7, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaexkvu54GhI"
      },
      "source": [
        "## SETTING THE THRESHOLD BETWEEN HIGH AND LOW ENERGY MUONS \r\n",
        "\r\n",
        "threshold = 3.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g34ecMCXraT"
      },
      "source": [
        "## LABELS FOR BINARY CLASSIFICATION FOR MUON NEUTRINO CLASSIFICATION\r\n",
        "## BEING PERFORMED ON A DATASET OF LOW ENERGY MUONS \r\n",
        "## BALANCING OUT THE MUON NEUTRINO CC EVENTS AND NON-MUON NEUTRINO CC EVENTS \r\n",
        "\r\n",
        "low_e_muons_labels = []                                              # empty array for the labels of the neutrino interactions, either 0s or 1s \r\n",
        "low_e_muons_input_1 = []                                             # empty array for the x-z view of the neutrino interaction\r\n",
        "low_e_muons_input_2 = []                                             # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_t2_8):\r\n",
        "\r\n",
        "  # opening the file in read only mode \r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    if (df['neutrino']['interaction'][i]) > 3:                        # interactions below or equal 3 are muon neutrino CC events\r\n",
        "\r\n",
        "        model = (df['cvnmap'][i]).reshape((2,100,80))                 # reshaping the images \r\n",
        "        low_e_muons_input_1.append(model[0])                          # apending the x-z view to the corresponding array\r\n",
        "        low_e_muons_input_2.append(model[1])                         # apending the y-z view to the corresponding array\r\n",
        "        low_e_muons_labels.append(int(0))                             # 0 for non muon neutrino CC events \r\n",
        "\r\n",
        "    else:\r\n",
        "      pass\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_20_4):\r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for j in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    if (df['neutrino']['interaction'][j]) <=3:                        # interactions below or equal 3 are muon neutrino CC events\r\n",
        "\r\n",
        "      # classifying muons with energy above the threshold \r\n",
        "      if (df['neutrino']['nuenergy'][j]) < threshold:\r\n",
        "\r\n",
        "        model = (df['cvnmap'][j]).reshape((2,100,80))                 # reshaping the images \r\n",
        "        low_e_muons_input_1.append(model[0])                          # apending the x-z view to the corresponding array\r\n",
        "        low_e_muons_input_2.append(model[1])                          # apending the y-z view to the corresponding array\r\n",
        "        low_e_muons_labels.append(int(1))                             # 1 for muon neutrino CC events \r\n",
        "\r\n",
        "      else:\r\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqHxcsjOo-pZ"
      },
      "source": [
        "## PLOTTING THE LABELS TO CHECK FOR BALANCE \r\n",
        "\r\n",
        "plt.hist(low_e_muons_labels)\r\n",
        "plt.title('Labels for muon neutrino classification on a dataset with low energy muons')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar-Eydz_Yc81"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "low_e_muons_labels, low_e_muons_input_1, low_e_muons_input_2 = shuffle_data(low_e_muons_labels, low_e_muons_input_1, low_e_muons_input_2)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "low_e_muons_input_1 = tf.expand_dims(low_e_muons_input_1, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "low_e_muons_input_2 = tf.expand_dims(low_e_muons_input_2, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1, test_input_1, val_input_1, train_input_2, test_input_2, val_input_2, train_labels, val_labels, test_labels = data(low_e_muons_input_1, low_e_muons_input_2, low_e_muons_labels, 0.8, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8gD-8D7YuCu"
      },
      "source": [
        "## CREATING THE MODEL FOR MUON NEUTRINO CLASSIFICATION\r\n",
        "\r\n",
        "model = concatenating(low_e_muons_input_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04SISb_XY02V"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history = model.fit(x=[train_input_1,train_input_2],\r\n",
        "                    y=train_labels, batch_size=64,                                 # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1,val_input_2],val_labels),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijRjhwvx7FR_"
      },
      "source": [
        "## EVALUATING THE ACCURACY AND LOSS OF THE MODEL \r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate([test_input_1,test_input_2],  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX28hRBf7J1a"
      },
      "source": [
        "## PLOTTING THE ACCURACY OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of muon neutrino classifier operating \\n on a dataset of low energy muons')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwporrBeSobb"
      },
      "source": [
        "## PLOTTING THE LOSS OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history.history['loss'], label='loss')\r\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Loss of muon neutrino classifier operating \\n on a dataset of low energy muons')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zne5MfZeZAyx"
      },
      "source": [
        "Once again, a similar accuracy is obtained for varying muon energy which is what was expected. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UsaGsaF4Ltg"
      },
      "source": [
        "<a name=\"4.4\"></a>\r\n",
        "\r\n",
        "## 4.5 Which variables in the metadata does the classifier performance depend? \r\n",
        "\r\n",
        "From the results obtained I think the main variables that affect the performance of the classifier are:\r\n",
        "\r\n",
        "1. Those variables that affect the image being fed into the network. This task is essentially a task within the field of computer vision, where the aim is to replication the human vision system in computers. Therefore those variables that affect what the computer is \"seeing\" is what will affect the performance of the classifier. \r\n",
        "\r\n",
        "2. The balance there is in the variables that are affecting the classifier. For example, it is important to have a balance between the labels or a balance between the \"messy\" and \"cleaner\" events to obtain accurate results rather than high accuracy results, where we could potentially have flase-trues. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YdwmrLod9OO"
      },
      "source": [
        "<a name=\"extension1\"></a>\r\n",
        "\r\n",
        "## 5. Extension 1: Machine learning algorithm to determine the energy of the neutrino.\r\n",
        "\r\n",
        "The value of the energy of the value cannot be classified into categories, we have a range of values and therefore this is a regression task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfyI4ce7Log_"
      },
      "source": [
        "## RETRIEVING THE FILES FOR THIS EXTENSION\r\n",
        "\r\n",
        "files_e1_2 = data_retriever(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBgKVTpDqRjI"
      },
      "source": [
        "Now we need to loop over all the files to get the energy labels and separate the x-z view from the y-z view. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoA8uabwMULA"
      },
      "source": [
        "## PREPARING THE DATA AND LABELS FOR THE MODEL \r\n",
        "\r\n",
        "nu_energy_labels=[]                                                      # empty array for the labels of the neutrino energy\r\n",
        "nu_energy_input_1=[]                                                     # empty array for the x-z view of the neutrino interaction\r\n",
        "nu_energy_input_2=[]                                                     # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_e1_2):\r\n",
        "\r\n",
        "  # opening the file in read only mode \r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['cvnmap'])):\r\n",
        "\r\n",
        "    model = df['cvnmap'][i].reshape((2,100,80))                           # reshaping the images \r\n",
        "    nu_energy_input_1.append(model[0])                                    # apending the x-z view to the corresponding array\r\n",
        "    nu_energy_input_2.append(model[1])                                    # apending the y-z view to the corresponding array\r\n",
        "    nu_energy_labels.append(int(df['neutrino']['nuenergy'][i]))           # appending the value of the energy to the labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhMqzg8lr6X8"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "nu_energy_input_1 = tf.expand_dims(nu_energy_input_1, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "nu_energy_input_2 = tf.expand_dims(nu_energy_input_2, axis = 3)\r\n",
        "\r\n",
        "# normalizing the energy labels \r\n",
        "nu_energy_labels=nu_energy_labels/np.max(nu_energy_labels)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1_nuenergy, test_input_1_nuenergy, val_input_1_nuenergy, train_input_2_nuenergy, test_input_2_nuenergy, val_input_2_nuenergy, train_labels_nuenergy, val_labels_nuenergy, test_labels_nuenergy = data(nu_energy_input_1, nu_energy_input_2, nu_energy_labels, 0.8, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYOQQFP9szke"
      },
      "source": [
        "Now that we have all the data we cab create the model, this uses different activation functions and metrics compared to the classification tasks. We use the mean squared error and mean absolute error as metrics. The optimizer used is the RMSprop algorithm. This maintains a moving (discounted) average of the square of gradients and divides the gradient by the root of this average. For regression tasks, a linear activation function should be used in the last layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNKD5HddraQv"
      },
      "source": [
        "def model_regression(model_input_1):\r\n",
        "  \r\n",
        "  \"\"\"\r\n",
        "  This function creates a simple Convolutional Neural Network model specifically for regression tasks in keras using the functional API for both the views of the \r\n",
        "  neutrino intercations, for the x-y view and the y-z view, and concatenates them. \r\n",
        "\r\n",
        "  Input:\r\n",
        "  - model_input_1: this is the image of the x-z view of the neutrino interaction. It is used to obtain the shape of the model input.\r\n",
        "\r\n",
        "  Output:\r\n",
        "  - model: CNN model of concatenated x-z and y-z views of the neutrino interactions.\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # Creates the CNN model for the x-z view of the neutrino interaction.\r\n",
        "  xz_input = Input(shape=np.shape(model_input_1)[1:])\r\n",
        "  xz_model = create_convolution_layers(xz_input, np.shape(model_input_1)[1:])\r\n",
        "\r\n",
        "  # Creates the CNN model for the y-z view of the neutrino interaction.\r\n",
        "  yz_input = Input(shape=np.shape(model_input_1)[1:])\r\n",
        "  yz_model = create_convolution_layers(yz_input, np.shape(model_input_1)[1:])\r\n",
        "\r\n",
        "  # Concatenates the two models \r\n",
        "  conv = concatenate([xz_model, yz_model])\r\n",
        "\r\n",
        "  # Flattens the concatenated models \r\n",
        "  conv = Flatten()(conv)\r\n",
        "\r\n",
        "  # Dense layers connect all the neurons of one layer to the ones in the next layer \r\n",
        "  dense = Dense(8)(conv)                                      \r\n",
        "  dense = Dropout(0.5)(dense)                                                   # 50% of the data is randomly excluded                                                   # 50% of the data is randomly excluded \r\n",
        "\r\n",
        "  output = Dense(1,                                                             # 1 is the dimensionality of the output space \r\n",
        "                  activation =\"linear\")(dense)                                  # linear as activation function. \r\n",
        "                                                                                # The input to the function is transformed into a value between 0.0 and 1.0.\r\n",
        "\r\n",
        "  # creates the model using the two model inputs \r\n",
        "  model = Model(inputs = [xz_input, yz_input], outputs = [output])\r\n",
        "\r\n",
        "  # compiles the final model\r\n",
        "  model.compile(loss='mse',\r\n",
        "                optimizer=tf.keras.optimizers.RMSprop(0.001),\r\n",
        "                metrics=['mae'                                                # mean absolute error\r\n",
        "                , 'mse'])                                                     # mean squared error                                \r\n",
        "\r\n",
        "  model.summary()\r\n",
        "\r\n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PKInBB-uPAF"
      },
      "source": [
        "## CREATING THE MODEL FOR ENERGY DETERMINATION \r\n",
        "\r\n",
        "model = model_regression(nu_energy_input_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPU5_4Diu6GH"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history_E1 = model.fit(x=[train_input_1_nuenergy,train_input_2_nuenergy],\r\n",
        "                    y=train_labels_nuenergy, batch_size=32,                        # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1_nuenergy,val_input_2_nuenergy],\r\n",
        "                                     val_labels_nuenergy),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMx-dUq2vnZ-"
      },
      "source": [
        "## EVALUATING THE MAE AND MSE OF THE MODEL \r\n",
        "\r\n",
        "test_loss, test_mae, test_mse = model.evaluate([test_input_1_nuenergy,test_input_2_nuenergy],  test_labels_nuenergy, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz3FuFb1wB_T"
      },
      "source": [
        "## PLOTTING THE MSE OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history_E1.history['mse'], label='mean squared error')\r\n",
        "plt.plot(history_E1.history['val_mse'], label = 'validation mean squared error')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('mean squared error')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('MSE of the model to determine neutrino energy')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjQTKxDzWKu7"
      },
      "source": [
        "## PLOTTING THE MAE OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history_E1.history['mae'], label='mean average error')\r\n",
        "plt.plot(history_E1.history['val_mae'], label = 'validation mean average error')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('mean average error')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('MAE of the model to determine neutrino energy')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74pkLgggwoDk"
      },
      "source": [
        "<a name=\"extension2\"></a>\r\n",
        "\r\n",
        "## 6. Extension 2: Machine learning algorithm to determine the flavour of the neutrino\r\n",
        "\r\n",
        "This is a similar task as the one performed in task 1 and 2 but instead of having a binary classification, we have more labels that represent the different types of flavours. We will classify these with the number 0, 1 and 2. As there are no tau neutrinos in the data, we can't classify these. \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8CrLzpNhxb-"
      },
      "source": [
        "## RETRIEVING THE NECESSARY FILES FOR THIS EXTENSION \r\n",
        "\r\n",
        "files_e2_1=data_retriever(80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGG133_AlD0R"
      },
      "source": [
        "## SPLITTING THE FILES\r\n",
        "\r\n",
        "files_e2_99, files_e2_01 = train_test_split(files_e2_1, train_size = 0.99)\r\n",
        "files_e2_90, files_e2_10 = train_test_split(files_e2_1, train_size = 0.90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mghguJTtGqv"
      },
      "source": [
        "e2_labels = []                                                              # empty array for the labels of the neutrino flavour\r\n",
        "e2_input_1 = []                                                             # empty array for the x-z view of the neutrino interaction\r\n",
        "e2_input_2 = []                                                             # empty array for the x-z view of the neutrino interaction\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_e2_01):                                        # using 1 file \r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    if df['neutrino']['interaction'][i] <=3:                              # this is for muon neutrinos, between 0-3\r\n",
        "\r\n",
        "      model = df['cvnmap'][i].reshape((2,100,80))                         # reshaping the images\r\n",
        "      e2_input_1.append(model[0])                                         # apending the x-z view to the corresponding array\r\n",
        "      e2_input_2.append(model[1])                                         # apending the y-z view to the corresponding array\r\n",
        "      e2_labels.append(int(1))                                            # appending a 1 to the labels for muon neutrinos \r\n",
        "\r\n",
        "    else:\r\n",
        "      pass\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_e2_1):                                         # using 80 files \r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction\r\n",
        "  for j in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    # this is for electron neutrinos, between 4-7\r\n",
        "    if df['neutrino']['interaction'][j] >=4 and df['neutrino']['interaction'][j] <= 7:\r\n",
        "\r\n",
        "      model = df['cvnmap'][j].reshape((2,100,80))                         # reshaping the images\r\n",
        "      e2_input_1.append(model[0])                                         # apending the x-z view to the corresponding array\r\n",
        "      e2_input_2.append(model[1])                                         # apending the y-z view to the corresponding array\r\n",
        "      e2_labels.append(int(2))                                            # appending a 2 to the labels for electron neutrinos \r\n",
        "\r\n",
        "    else:\r\n",
        "      pass\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_e2_10):\r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    if df['neutrino']['interaction'][i] > 7:  \r\n",
        "\r\n",
        "      model = df['cvnmap'][i].reshape((2,100,80))                         # reshaping the images\r\n",
        "      e2_input_1.append(model[0])                                         # apending the x-z view to the corresponding array\r\n",
        "      e2_input_2.append(model[1])                                         # apending the y-z view to the corresponding array\r\n",
        "      e2_labels.append(int(0))                                            # appending a 0 to the labels for non-muon and non-electron neutrinos \r\n",
        "\r\n",
        "    else:\r\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGaDDOBvyl11"
      },
      "source": [
        "## PLOTTING THE LABELS TO CHECK IF IT IS BALANCED \r\n",
        "\r\n",
        "plt.hist(e2_labels)\r\n",
        "plt.title('Labels for flavour classification')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFCX_2Fx3Jum"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "e2_labels, e2_input_1, e2_input_2 = shuffle_data(e2_labels, e2_input_1, e2_input_2)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "e2_input_1 = tf.expand_dims(e2_input_1, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "e2_input_2 = tf.expand_dims(e2_input_2, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1_e2, test_input_1_e2, val_input_1_e2, train_input_2_e2, test_input_2_e2, val_input_2_e2, train_labels_e2, val_labels_e2, test_labels_e2 = data(e2_input_1, e2_input_2, e2_labels, 0.8, 0.8)\r\n",
        "\r\n",
        "# to be able to use categorical cross entropy \r\n",
        "train_labels_e2 = tf.keras.utils.to_categorical(train_labels_e2, 3)\r\n",
        "test_labels_e2 = tf.keras.utils.to_categorical(test_labels_e2, 3)\r\n",
        "val_labels_e2 = tf.keras.utils.to_categorical(val_labels_e2, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A81ZoeuT_alD"
      },
      "source": [
        "This isn't a binary classification so the optimizer has to be changed to categorical crossentropy and in the last dense layer there has to be 3 nodes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcAecdk7-rTL"
      },
      "source": [
        "# Creates the CNN model for the x-z view of the neutrino interaction.\r\n",
        "xz_input = Input(shape=np.shape(e2_input_1)[1:])\r\n",
        "xz_model = create_convolution_layers(xz_input, np.shape(e2_input_1)[1:])\r\n",
        "\r\n",
        "# Creates the CNN model for the y-z view of the neutrino interaction.\r\n",
        "yz_input = Input(shape=np.shape(e2_input_1)[1:])\r\n",
        "yz_model = create_convolution_layers(yz_input, np.shape(e2_input_1)[1:])\r\n",
        "\r\n",
        "# Concatenates the two models \r\n",
        "conv = concatenate([xz_model, yz_model])\r\n",
        "\r\n",
        "# Flattens the concatenated models \r\n",
        "conv = Flatten()(conv)\r\n",
        "\r\n",
        "# Dense layers connect all the neurons of one layer to the ones in the next layer \r\n",
        "dense = Dense(8,                                                              # 64 is the dimensionality of the output space\r\n",
        "              activation = \"relu\")(conv)                                      # Rectified Linear Unit as activation function\r\n",
        "dense = Dropout(0.5)(dense)                                                   # 50% of the data is randomly excluded \r\n",
        "\r\n",
        "output = Dense(3,                                                             # 1 is the dimensionality of the output space \r\n",
        "                activation =\"sigmoid\")(dense)                                  # sigmoid as activation function. \r\n",
        "                                                                              # The input to the function is transformed into a value between 0.0 and 1.0.\r\n",
        "\r\n",
        "# creates the model using the two model inputs \r\n",
        "model = Model(inputs = [xz_input, yz_input], outputs = [output])\r\n",
        "\r\n",
        "# compiles the final model\r\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,                       # using binary crossentropy as a loss function as we are doing a binary classification\r\n",
        "# adam is used for optimization algorithm for stochastic gradient descent for training deep learning models\r\n",
        "              optimizer='adam',                                               \r\n",
        "              metrics=['accuracy'])                                           # using the accuracy as a metric to evaluate the model \r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QzKYJa39vu8"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history_elec = model.fit(x=[train_input_1_e2,train_input_2_e2],\r\n",
        "                    y=train_labels_e2, batch_size=64,                              # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1_e2,val_input_2_e2],val_labels_e2),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8tgUIc4-G1I"
      },
      "source": [
        "## EVALUATING THE ACCURACY AND LOSS OF THE MODEL \r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate([test_input_1_e2,test_input_2_e2],  test_labels_e2, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITr4LicK-U-L"
      },
      "source": [
        "## PLOTTING THE ACCURACY OF THE MODEL\r\n",
        "\r\n",
        "plt.plot(history_elec.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history_elec.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of neutrino flavour classifier')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KuhI9StAH32"
      },
      "source": [
        "## PLOTTING THE LOSS OF THE MODEL\r\n",
        "\r\n",
        "plt.plot(history_elec.history['loss'], label='loss')\r\n",
        "plt.plot(history_elec.history['val_loss'], label = 'val_loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Loss of neutrino flavour classifier')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P8Wa2ngA57T"
      },
      "source": [
        "<a name=\"extension3\"></a>\r\n",
        "\r\n",
        "## 7. Extension 3: Machine learning algorithm to determine $y=$ lepton energy over neutrino energy\r\n",
        "\r\n",
        "This is similar to extension 1 but not we have to need an algorithm to determine lepton energy over neutrino energy. This is again a regression task. \r\n",
        "\r\n",
        "As this is a division, the first step is to find if there is any interaction that has lepton energy or neutrino energy that is equal to 0. For this we will use the 200 files. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsTvLTlpBFU6"
      },
      "source": [
        "## RETRIEVING THE FILES FOR THIS EXTENSION \r\n",
        "files_e3=data_retriever(200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbCArAP71dCv"
      },
      "source": [
        "## FINDING 0 LEPTON AND NEUTRINO ENERGY  \r\n",
        "\r\n",
        "lep=[]                                                               # empty array to store the number of the interaction with 0 lepton energy\r\n",
        "nu=[]                                                                # empty array to store the number of the interaction with 0 neutrino energy\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_e3):\r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['cvnmap'])):\r\n",
        "\r\n",
        "    # if the lepton energy is 0 it appends the number of the interaction to the array\r\n",
        "    if df['neutrino']['lepenergy'][i] == 0:\r\n",
        "      lep.append(df['neutrino']['interaction'][i])\r\n",
        "\r\n",
        "    else:\r\n",
        "      pass\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['cvnmap'])):\r\n",
        "\r\n",
        "    # if the lepton energy is 0 it appends the number of the interaction to the array\r\n",
        "    if df['neutrino']['nuenergy'][i] == 0:\r\n",
        "      nu.append(df['neutrino']['interaction'][i])\r\n",
        "\r\n",
        "    else:\r\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_HfeY6_CpbQ"
      },
      "source": [
        "There is 0 lepton and neutrino energy for interaction number 15. These need to be excluded from the code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDmSvywwC3ZR"
      },
      "source": [
        "Now that this has been identified we can proceed with the task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLg6ZNY6C22K"
      },
      "source": [
        "## RETRIEVING THE NECESSARY FILES \r\n",
        "\r\n",
        "files_e3_2=data_retriever(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDEtJH8zwxLw"
      },
      "source": [
        "# LABELS AND IMAGES INPUT FOR MODEL \r\n",
        "\r\n",
        "y_energy_labels = []                                                      # empty array for values of lepton energy over neutrino energy \r\n",
        "y_energy_input_1=[]                                                       # empty array for the x-z view of the neutrino interaction\r\n",
        "y_energy_input_2=[]                                                       # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_e3_2):\r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of the images to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['cvnmap'])):\r\n",
        "\r\n",
        "    # excluding interaction 15 from the code \r\n",
        "    if df['neutrino']['interaction'][i] < 15 or df['neutrino']['interaction'][i] == 16:\r\n",
        "      \r\n",
        "      # calculating lepton energy over neutrino energy \r\n",
        "      y = df['neutrino']['lepenergy'][i] / df['neutrino']['nuenergy'][i] \r\n",
        "      \r\n",
        "      y_energy_labels.append(y)                                           # apending y to the label array\r\n",
        "      model = df['cvnmap'][i].reshape((2,100,80))                         # reshaping the images\r\n",
        "      y_energy_input_1.append(model[0])                                   # apending the x-z view to the corresponding array\r\n",
        "      y_energy_input_2.append(model[1])                                   # apending the y-z view to the corresponding array\r\n",
        "    else:\r\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbuYg8vPETHc"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "y_energy_input_1 = tf.expand_dims(y_energy_input_1, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "y_energy_input_2 = tf.expand_dims(y_energy_input_2, axis = 3)\r\n",
        "\r\n",
        "# normalizing the energy labels \r\n",
        "y_energy_labels=y_energy_labels/np.max(y_energy_labels)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_input_1_y_energy, test_input_1_y_energy, val_input_1_y_energy, train_input_2_y_energy, test_input_2_y_energy, val_input_2_y_energy, train_labels_y_energy, val_labels_y_energy, test_labels_y_energy = data(y_energy_input_1, y_energy_input_2, y_energy_labels, 0.8, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTgW1iXREbTQ"
      },
      "source": [
        "## CREATING THE MODEL FOR LEPTON ENERGY OVER NEUTRINO ENERGY DETERMINATION \r\n",
        "\r\n",
        "model = model_regression(y_energy_input_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XxVzNnKFGSq"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history_E3 = model.fit(x=[train_input_1_y_energy,train_input_2_y_energy],\r\n",
        "                    y=train_labels_y_energy, batch_size=32,                        # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_input_1_y_energy,val_input_2_y_energy],\r\n",
        "                                     val_labels_y_energy),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsA4EAoMjR1c"
      },
      "source": [
        "## EVALUATING THE MAE AND MSE OF THE MODEL \r\n",
        "\r\n",
        "test_loss, test_mae, test_mse = model.evaluate([test_input_1_y_energy,test_input_2_y_energy],  test_labels_y_energy, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qmsGs_jjdms"
      },
      "source": [
        "## PLOTTING THE MSE OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history_E3.history['mse'], label='mean squared error')\r\n",
        "plt.plot(history_E3.history['val_mse'], label = 'validation mean squared error')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('mean squared error')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('MSE of the model to determine \\n lepton energy over neutrino energy')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOc5W6Y5h7Es"
      },
      "source": [
        "## PLOTTING THE MAE OF THE MODEL \r\n",
        "\r\n",
        "plt.plot(history_E3.history['mae'], label='mean average error')\r\n",
        "plt.plot(history_E3.history['val_mae'], label = 'validation mean average error')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('mean average error')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('MAE of the model to determine \\n lepton energy over neutrino energy')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g9bxcf1nTR8"
      },
      "source": [
        "<a name=\"extension5\"></a>\r\n",
        "\r\n",
        "## 8. Extension 5: Machine learning algorithm to determine the interaction mode\r\n",
        "\r\n",
        "In this section we will be developing an algorithm to classify the neutrino interaction model. This is another classification task with five groups in this case, the same procedure as extension 2 will be used. The different interaction modes and the corresponding labels are shown below: \r\n",
        "\r\n",
        "- Label 0 for charged-current quasi-elastic events \r\n",
        "\r\n",
        "- Label 1 for charged-current resonant events \r\n",
        "\r\n",
        "- Label 2 for charged-current deep-inelastic scattering \r\n",
        "\r\n",
        "- Label 3 for charged-current other events \r\n",
        "\r\n",
        "- Label 4 for neutral charged current events "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCZG5UYsjveb"
      },
      "source": [
        "## RETRIEVING THE NECESSARY FILES FOR THIS EXTENSION \r\n",
        "\r\n",
        "files_5=data_retriever(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7aS7i5ly603"
      },
      "source": [
        "## OBTAINING THE LABELS FOR THE INTERACTION MODE \r\n",
        "\r\n",
        "int_mode_labels=[]                   # empty array for the lables corresponding to the interaction mode \r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_5):\r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename)\r\n",
        "               \r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    if (df['neutrino']['interaction'][i]) == 0 or (df['neutrino']['interaction'][i]) == 4 or (df['neutrino']['interaction'][i]) == 8:\r\n",
        "      int_mode_labels.append(int(0)) # appending 0 for CC QE events\r\n",
        "\r\n",
        "    elif (df['neutrino']['interaction'][i]) == 1 or (df['neutrino']['interaction'][i]) == 5 or (df['neutrino']['interaction'][i]) == 9:\r\n",
        "      int_mode_labels.append(int(1)) # appending 1 for CC RES events  \r\n",
        "    \r\n",
        "    elif (df['neutrino']['interaction'][i]) == 2 or (df['neutrino']['interaction'][i]) == 6 or (df['neutrino']['interaction'][i]) == 10:\r\n",
        "      int_mode_labels.append(int(2)) # appending 2 for CC DIS events  \r\n",
        "\r\n",
        "    elif (df['neutrino']['interaction'][i]) == 3 or (df['neutrino']['interaction'][i]) == 7 or (df['neutrino']['interaction'][i]) == 11:\r\n",
        "      int_mode_labels.append(int(3)) # appending 3 for CC other events \r\n",
        "\r\n",
        "    elif (df['neutrino']['interaction'][i]) == 12 or (df['neutrino']['interaction'][i]) == 13:\r\n",
        "      int_mode_labels.append(int(4)) # appending 4 for NC events\r\n",
        "\r\n",
        "    else:\r\n",
        "      pass "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifr_MFfnqARG"
      },
      "source": [
        "Now that we have the labels for the interaction mode, we need to make sure the labels are balanced. We will check the balance by plotting the labels on a histogram. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d64eK6IKol5R"
      },
      "source": [
        "## CHECKING IF THE LABELS ARE BALANCED \r\n",
        "\r\n",
        "plt.hist(int_mode_labels)\r\n",
        "plt.title('Imbalanced labels for neutrino interaction mode')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX3l-BhzqYam"
      },
      "source": [
        "It can clearly be seen that the labels are not balanced. In order to balance these, we will use the same method we have been using for the other tasks. We will loop over more files for the label with least events and over less files for the labels with more events. This is a more complex balance to achieve as we are dealing with 5 interaction modes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEz5dSjM3Y2l"
      },
      "source": [
        "## SPLITTING THE FILES TO ITERATE OVER IN ORDER TO BALANCE THE LABELS\r\n",
        "\r\n",
        "files_5_80, files_5_20 = train_test_split(files_5, train_size = 0.8, shuffle = False)\r\n",
        "files_5_95, files_5_05 = train_test_split(files_5, train_size = 0.95, shuffle = False)\r\n",
        "files_5_75, files_5_25 = train_test_split(files_5, train_size = 0.75, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDtbkaRz1xGo"
      },
      "source": [
        "## GETTING THE LABELS FOR THE INTERACTION MODE CLASSIFIER AND BALANCING THEM \r\n",
        "\r\n",
        "int_mode_labels_b=[]                                                # empty array to store the labels of the interaction mode\r\n",
        "int_mode_input_1=[]                                                 # empty array for the x-z view of the neutrino interaction\r\n",
        "int_mode_input_2=[]                                                 # empty array for the y-z view of the neutrino interaction\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_5_25):                                   # using 0-4 files \r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction \r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    # if the neutrino interaction number is 0, 4 or 8, the events is a CC QE event \r\n",
        "    if (df['neutrino']['interaction'][i]) == 0 or (df['neutrino']['interaction'][i]) == 4 or (df['neutrino']['interaction'][i]) == 8:\r\n",
        "\r\n",
        "      model = df['cvnmap'][i].reshape((2,100,80))                  # reshaping the images\r\n",
        "      int_mode_input_1.append(model[0])                            # apending the x-z view to the corresponding array\r\n",
        "      int_mode_input_2.append(model[1])                            # apending the y-z view to the corresponding array\r\n",
        "      int_mode_labels_b.append(int(0))                             # appending 0 for CC QE events\r\n",
        "\r\n",
        "    else:\r\n",
        "      pass\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_5_20):                                  # using 0-3 files \r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction\r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    # if the neutrino interaction number is 1, 5 or 9, the events is a CC RES event \r\n",
        "    if (df['neutrino']['interaction'][i]) == 1 or (df['neutrino']['interaction'][i]) == 5 or (df['neutrino']['interaction'][i]) == 9:\r\n",
        "\r\n",
        "      int_mode_labels_b.append(int(1))                             # appending 1 for CC RES events \r\n",
        "      model = df['cvnmap'][i].reshape((2,100,80))                  # reshaping the images\r\n",
        "      int_mode_input_1.append(model[0])                            # apending the x-z view to the corresponding array\r\n",
        "      int_mode_input_2.append(model[1])                            # apending the y-z view to the corresponding array\r\n",
        "\r\n",
        "    else:\r\n",
        "      pass\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_5_05):                                  # using 0-1 files \r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction\r\n",
        "  for i in range(len(df['neutrino']['interaction'])): \r\n",
        "    \r\n",
        "    # if the neutrino interaction number is 2, 6 or 10, the events is a CC DIS event \r\n",
        "    if (df['neutrino']['interaction'][i]) == 2 or (df['neutrino']['interaction'][i]) == 6 or (df['neutrino']['interaction'][i]) == 10:\r\n",
        "\r\n",
        "      int_mode_labels_b.append(int(2))                             # appending 2 for CC DIS events  \r\n",
        "      model = df['cvnmap'][i].reshape((2,100,80))                  # reshaping the images\r\n",
        "      int_mode_input_1.append(model[0])                            # apending the x-z view to the corresponding array\r\n",
        "      int_mode_input_2.append(model[1])                            # apending the y-z view to the corresponding array\r\n",
        "\r\n",
        "    else:\r\n",
        "      pass\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_5):                                     # using 0-15 files \r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction\r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    # if the neutrino interaction number is 3, 7 or 11, the events is a CC other event\r\n",
        "    if (df['neutrino']['interaction'][i]) == 3 or (df['neutrino']['interaction'][i]) == 7 or (df['neutrino']['interaction'][i]) == 11:\r\n",
        "\r\n",
        "      int_mode_labels_b.append(int(3))                             # appending 3 for CC other events \r\n",
        "      model = df['cvnmap'][i].reshape((2,100,80))                  # reshaping the images\r\n",
        "      int_mode_input_1.append(model[0])                            # apending the x-z view to the corresponding array\r\n",
        "      int_mode_input_2.append(model[1])                            # apending the y-z view to the corresponding array\r\n",
        "\r\n",
        "    else:\r\n",
        "      pass\r\n",
        "\r\n",
        "# iterating over the array of file names to obtain the lables and the input images for each interaction\r\n",
        "for filename in tqdm(files_5_25): # using 0-4 files\r\n",
        "\r\n",
        "  # opening the file in read only mode\r\n",
        "  df=h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # iterating over the length of neutrino interactions to obtain the labels and input images for each interaction\r\n",
        "  for i in range(len(df['neutrino']['interaction'])):\r\n",
        "\r\n",
        "    # if the neutrino interaction number is 12 or 13, the events is a NC other event\r\n",
        "    if (df['neutrino']['interaction'][i]) == 12 or (df['neutrino']['interaction'][i]) == 13:\r\n",
        "\r\n",
        "      int_mode_labels_b.append(int(4))                             # appending 4 for NC events\r\n",
        "      model = df['cvnmap'][i].reshape((2,100,80))                  # reshaping the images\r\n",
        "      int_mode_input_1.append(model[0])                            # apending the x-z view to the corresponding array\r\n",
        "      int_mode_input_2.append(model[1])                            # apending the y-z view to the corresponding array\r\n",
        "      \r\n",
        "    else:\r\n",
        "      pass "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXMUqFHCtZHu"
      },
      "source": [
        "## CHECKING IF THE LABELS ARE BALANCED \r\n",
        "\r\n",
        "plt.hist(int_mode_labels_b)\r\n",
        "plt.title('Balanced labels for neutrino interaction mode')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO-nV4xVtdDj"
      },
      "source": [
        "The labels are not perfectly balanced but they are a lot more balanced than the initial labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0GX1o3dtyux"
      },
      "source": [
        "## PREPARING THE DATA TO FEED INTO THE NEURAL NETWORK\r\n",
        "\r\n",
        "# shuffling the labels and images \r\n",
        "int_mode_labels_b, int_mode_input_1, int_mode_input_2 = shuffle_data(int_mode_labels_b, int_mode_input_1, int_mode_input_2)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the x-z view of the neutrino interaction\r\n",
        "int_mode_input_1 = tf.expand_dims(int_mode_input_1, axis = 3)\r\n",
        "\r\n",
        "# expanding the dimensions of the images corresponding to the y-z view of the neutrino interaction\r\n",
        "int_mode_input_2 = tf.expand_dims(int_mode_input_2, axis = 3)\r\n",
        "\r\n",
        "# preparing the training, testing and validation data\r\n",
        "train_int_mode_input_1, test_int_mode_input_1, val_int_mode_input_1, train_int_mode_input_2, test_int_mode_input_2, val_int_mode_input_2, train_int_mode_labels_b, val_int_mode_labels_b, test_int_mode_labels_b = data(int_mode_input_1, int_mode_input_2, int_mode_labels_b, 0.8, 0.8)\r\n",
        "\r\n",
        "# to be able to use categorical cross entropy \r\n",
        "train_int_mode_labels_b = tf.keras.utils.to_categorical(train_int_mode_labels_b, 5)\r\n",
        "test_int_mode_labels_b = tf.keras.utils.to_categorical(test_int_mode_labels_b, 5)\r\n",
        "val_int_mode_labels_b = tf.keras.utils.to_categorical(val_int_mode_labels_b, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCDO9i8HvysX"
      },
      "source": [
        "We won't be using the definition to create the model as we need to change the number of nodes in the last dense layer to be 5, as well as the loss, which has to be categorical cross entropy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXm_0_2rvx6F"
      },
      "source": [
        "# Creates the CNN model for the x-z view of the neutrino interaction.\r\n",
        "xz_input = Input(shape=np.shape(int_mode_input_1)[1:])\r\n",
        "xz_model = create_convolution_layers(xz_input, np.shape(int_mode_input_1)[1:])\r\n",
        "\r\n",
        "# Creates the CNN model for the y-z view of the neutrino interaction.\r\n",
        "yz_input = Input(shape=np.shape(int_mode_input_1)[1:])\r\n",
        "yz_model = create_convolution_layers(yz_input, np.shape(int_mode_input_1)[1:])\r\n",
        "\r\n",
        "# Concatenates the two models \r\n",
        "conv = concatenate([xz_model, yz_model])\r\n",
        "\r\n",
        "# Flattens the concatenated models \r\n",
        "conv = Flatten()(conv)\r\n",
        "\r\n",
        "# Dense layers connect all the neurons of one layer to the ones in the next layer \r\n",
        "dense = Dense(8,                                                              # 64 is the dimensionality of the output space\r\n",
        "              activation = \"relu\")(conv)                                      # Rectified Linear Unit as activation function\r\n",
        "dense = Dropout(0.5)(dense)                                                   # 50% of the data is randomly excluded \r\n",
        "\r\n",
        "output = Dense(5,                                                             # 1 is the dimensionality of the output space \r\n",
        "                activation =\"sigmoid\")(dense)                                  # sigmoid as activation function. \r\n",
        "                                                                              # The input to the function is transformed into a value between 0.0 and 1.0.\r\n",
        "\r\n",
        "# creates the model using the two model inputs \r\n",
        "model = Model(inputs = [xz_input, yz_input], outputs = [output])\r\n",
        "\r\n",
        "# compiles the final model\r\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,                       # using binary crossentropy as a loss function as we are doing a binary classification\r\n",
        "# adam is used for optimization algorithm for stochastic gradient descent for training deep learning models\r\n",
        "              optimizer='adam',                                               \r\n",
        "              metrics=['accuracy'])                                           # using the accuracy as a metric to evaluate the model \r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UoRbRJbwibn"
      },
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",                       # quantity to be monitored\r\n",
        "                                        mode =\"min\",                               # training will stop when val_loss is at its minimum\r\n",
        "                                        patience = 5,                              # number of epochs with no improvement after which training will be stopped\r\n",
        "                                        restore_best_weights = True)               # restore to the val_loss of the first epoch from which there is no improvement \r\n",
        "\r\n",
        "history_elec = model.fit(x=[train_int_mode_input_1,train_int_mode_input_2],\r\n",
        "                    y=train_int_mode_labels_b, batch_size=64,                      # number of training examples utilized in one iteration\r\n",
        "                    epochs=50,                                                     # 1 epoch: when the entire dataset is passed forward and backward through the CNN\r\n",
        "                    validation_data=([val_int_mode_input_1,val_int_mode_input_2],val_int_mode_labels_b),\r\n",
        "                    callbacks =[earlystopping] )                                   # used to avoid overtraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlqR_J6gRhk9"
      },
      "source": [
        "## EVALUATING THE ACCURACY AND LOSS OF THE MODEL \r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate([test_int_mode_input_1,test_int_mode_input_2],  test_int_mode_labels_b, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnzuJcefzODv"
      },
      "source": [
        "## PLOTTING THE ACCURACY OF THE MODEL\r\n",
        "\r\n",
        "plt.plot(history_elec.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history_elec.history['val_accuracy'], label = 'val_accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Accuracy of neutrino interaction mode classifier')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVC0W41Lzhth"
      },
      "source": [
        "## PLOTTING THE LOSS OF THE MODEL\r\n",
        "\r\n",
        "plt.plot(history_elec.history['loss'], label='loss')\r\n",
        "plt.plot(history_elec.history['val_loss'], label = 'val_loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.grid()\r\n",
        "plt.title('Loss of neutrino interaction mode classifier')\r\n",
        "#f.savefig(\"dataset.png\")                # saves the figure to be able to download it to a desktop \r\n",
        "#files.download(\"dataset.png\")           # saves the figure to the desktop and sets the name for it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S2WQuQPzscm"
      },
      "source": [
        "The accuracy of the classifier is very low which could be due to the computational limitations of the task, as the RAM crashed for if the network operated on a larger dataset. This could be repeated with a more complex network operating on a larger dataset to improve the improve the performance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch46uWm_1XK4"
      },
      "source": [
        "<a name=\"conc\"></a>\r\n",
        "\r\n",
        "## 9. Conclusion\r\n",
        "\r\n",
        "A multi-view CNN was used to perform different tasks on a dataset containing information on neutrino\r\n",
        "interactions. The first objective was to develop a machine learning algorithm to classify muon neutrinos. The\r\n",
        "initial classifier achieved an accuracy 82.50% and a loss of 0.4116. It was found that the dataset being used to\r\n",
        "train this classifier contained approximately 50% of DIS events and only 13% QE events. The accuracy and the\r\n",
        "loss improved by 3.2% and 10.6% respectively when the classifier was operated on a dataset of equal QE and\r\n",
        "DIS events. The accuracy and the loss improved even more, by 11.2% and 43.3% respectively when it operated\r\n",
        "on a dataset uniquely containing QE events. When the classifier was tested on datasets of high and low energy\r\n",
        "muons and neutrinos, no significant change in performance was observed. This demonstrated the that the\r\n",
        "performance of the model is dependent on those variables that affect the images. The importance of having\r\n",
        "a balanced dataset was explored, in the contrary case false positives were obtained. Lastly, the model was\r\n",
        "used to classify neutrino flavours and interaction modes and to detect neutrino energies and lepton energy\r\n",
        "over neutrino energy. Overall, the results obtained for all the tasks are acceptable but were constrained by\r\n",
        "computational limitations. The results can be improved using a larger dataset, which is only possible with a\r\n",
        "more powerful GPU and more RAM space. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paxTdYX81jJf"
      },
      "source": [
        "<a name=\"ref\"></a>\r\n",
        "\r\n",
        "## 10. References\r\n",
        "\r\n",
        "[1] E. Nurse, A. Korn. PHAS0040 Nuclear and Particle Physics, University College London (UCL). pp 5-6, 2020.\r\n",
        "\r\n",
        "\r\n",
        "[2] Emsley, John. Nature's Building Blocks ((Hardcover, First Edition) ed.). Oxford University Press. pp. 521–22. ISBN 978-\r\n",
        "0-19-850340-8, 2001.\r\n",
        "\r\n",
        "\r\n",
        "[3] R. Oerter. The Theory of Almost Everything: The Standard Model, the Unsung Triumph of Modern Physics (Kindle ed.).\r\n",
        "Penguin Group. p. 2. ISBN 978-0-13-236678-6, 2006.\r\n",
        "\r\n",
        "\r\n",
        "[4] Butterworth, J. The Standard Model: how far can it go and how can we tell?. Philosophical Transactions of the Royal\r\n",
        "Society A: Mathematical, Physical and Engineering Sciences, 374(2075), p.20150260, 2016\r\n",
        "\r\n",
        "\r\n",
        "[5] Rosario Rocco, D. Muon Neutrino Disappearance in NOvA with a Deep Convolutional Neural Network Classifier, 2016\r\n",
        "\r\n",
        "\r\n",
        "[6] H. Becquerel. Compt. Rend., 1896.\r\n",
        "\r\n",
        "\r\n",
        "[7] W. Pauli. Pauli Letter Collection, CERN, 1930.\r\n",
        "\r\n",
        "\r\n",
        "[8] J. Chadwick. The Existence of a Neutron. Royal Society of London Proceedings Series A, 136:692–708, June 1932.\r\n",
        "\r\n",
        "\r\n",
        "[9] E. Fermi. Versuch einer Theorie der β-Strahlen. I. Zeitschrift fur Physik, 88:161– 177, March 1934.\r\n",
        "\r\n",
        "\r\n",
        "[10] C. L. Cowan Jr., F. Reines, F. B. Harrison, H. W. Kruse, and A. D. McGuire. Detection of the free neutrino: A\r\n",
        "confirmation. Science, 124(3212):pp. 103–104, 1956.\r\n",
        "\r\n",
        "\r\n",
        "[11] E. Vitagliano, J. Redondo, G. Raffelta et al. Solar neutrino flux at keV energies. 2017.\r\n",
        "\r\n",
        "\r\n",
        "[12] Z. Szadowski, D. Glas, K. Pytel et al. Artificial Neural Networks as a FPGA Trigger for a Detection of NeutrinoInduced Air Showers. 2016.\r\n",
        "\r\n",
        "\r\n",
        "[13] Z. Maki, M. Nakagawa, S. Sakata et al. Remarks on the Unified Model of Elementary Particles. 1962.\r\n",
        "\r\n",
        "\r\n",
        "[14] F. Halzen and A.D. Martin. Quarks and leptons: an introductory course in modern particle physics. Wiley, 1984.\r\n",
        "\r\n",
        "\r\n",
        "[15] Q. Ho-Kim and X.Y. Pham. Elementary Particles and Their Interactions: Concepts and Phenomena. Springer Berlin\r\n",
        "Heidelberg, 2010.\r\n",
        "\r\n",
        "\r\n",
        "[16] Stuart Charles Fuess. Neutrino-proton and anti-neutrino-proton elastic scattering. Technical report, Illinois Univ., Urbana, IL (United States), 1981.\r\n",
        "\r\n",
        "\r\n",
        "[17] C.H. Llewellyn Smith. Neutrino reactions at accelerator energies. Physics Reports, 3(5):261 – 379, 1972.\r\n",
        "\r\n",
        "\r\n",
        "[18] D. Rein, L. M. Sehgal. Neutrino-excitation of baryon resonances and single pion production. Annals of Physics,\r\n",
        "133(1):79–153, 1981.\r\n",
        "\r\n",
        "\r\n",
        "[19] MAG Aivazis, Fredrick I Olness, and Wu-Ki Tung. Leptoproduction of heavy quarks. i. general formalism and\r\n",
        "kinematics of charged current and neutral current production processes. Physical Review D, 50(5):3085, 1994.\r\n",
        "\r\n",
        "\r\n",
        "[20] Y. Fukuda , T.Hayakawa , E.Ichihara et al. Evidence for oscillation of atmospheric neutrinos. 1998.\r\n",
        "18014458, January 2021\r\n",
        "\r\n",
        "\r\n",
        "[21] F. Capozzi, E. Lisi and A. Marrone et al. Neutrino masses and mixings: Status of known and unknown 3ν parameters.\r\n",
        "2016.\r\n",
        "\r\n",
        "\r\n",
        "[22] J. Sonneveld Searches for physics beyond the standard model at the LHC. 2018.\r\n",
        "\r\n",
        "\r\n",
        "[23] G.N Perdue, A. Ghosh, M. Wospakrik et al. Reducing model bias in a deep learning classifier using domain\r\n",
        "adversarial neural networks in MINERνA experiment. 2018.\r\n",
        "\r\n",
        "\r\n",
        "[24] M. Brenzke Development and Optimization of Deep Neural Networks for Energy Reconstruction of Muon Events in\r\n",
        "IceCube. 2017.\r\n",
        "\r\n",
        "\r\n",
        "[25] Y. Fukud, T. Hayakawa, E. Ich. et al. The Super-Kamiokande detector. 2002.\r\n",
        "\r\n",
        "\r\n",
        "[26] R. Acciarri, M. A. Acero, M. Adamowski et al. Long-Baseline Neutrino Facility (LBNF) and Deep Underground\r\n",
        "Neutrino Experiment (DUNE) Conceptual Design Report Volume 1: The LBNF and DUNE Projects. 2016.\r\n",
        "\r\n",
        "\r\n",
        "[27] A. Aurisano, A. Radovic, D. Rocco et al. A Convolutional Neural Network Neutrino Event Classifier. 2016.\r\n",
        "\r\n",
        "\r\n",
        "[28] P Adamson, K Anderson, M Andrews, R Andrews, I Anghel, D Augustine, A Aurisano, S Avvakumov, DS Ayres, B\r\n",
        "Baller, et al. The numi neutrino beam. Nuclear Instruments and Methods in Physics Research Section A: Accelerators,\r\n",
        "Spectrometers, Detectors and Associated Equipment, 806:279–306, 2016.\r\n",
        "\r\n",
        "\r\n",
        "[29] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard et al., Backpropagation applied to\r\n",
        "handwritten zip code recognition, Neural Comput. 1 (Dec., 1989) 541–551.\r\n",
        "\r\n",
        "\r\n",
        "[30] Y. Guo et al. Deep learning for visual understanding: A review. Neurocomputing, 187, 11 2015.\r\n",
        "\r\n",
        "\r\n",
        "[31] K. O’Shea and Ryan Nash. An introduction to convolutional neural networks, 2015.\r\n",
        "\r\n",
        "\r\n",
        "[32] Team, K.. Keras Documentation: The Functional API. [online] Keras.io. Available at:\r\n",
        "https://keras.io/guides/functional_api/#multi-input-and-multi-output-models, 2021 [Accessed 01 January 2021]. \r\n",
        "\r\n",
        "[33] Liu, S. and Deng, W. Very deep convolutional neural network-based image classification using small training sample\r\n",
        "size. 2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR), 2015.\r\n",
        "\r\n",
        "\r\n",
        "[34] He, K., Zhang, X., Ren, S. and Sun, J. Deep Residual Learning for Image Recognition. 2016 IEEE Conference on\r\n",
        "Computer Vision and Pattern Recognition (CVPR), 2016.\r\n",
        "\r\n",
        "\r\n",
        "[35] Uddin, M. Addressing Accuracy Paradox Using Enhanched Weighted Performance Metric in Machine Learning. 2019\r\n",
        "Sixth HCT Information Technology Trends (ITT), 2019.\r\n",
        "\r\n",
        "\r\n",
        "[36] H.Sekiya J. Phys.: Conf. Ser. 718 062052, 2016"
      ]
    }
  ]
}